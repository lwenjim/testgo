* 
* ==> Audit <==
* |--------------|----------------|----------|------|---------|-------------------------------|-------------------------------|
|   Command    |      Args      | Profile  | User | Version |          Start Time           |           End Time            |
|--------------|----------------|----------|------|---------|-------------------------------|-------------------------------|
| update-check |                | minikube | jim  | v1.22.0 | Thu, 06 Jan 2022 18:31:15 CST | Thu, 06 Jan 2022 18:31:17 CST |
| update-check |                | minikube | jim  | v1.22.0 | Thu, 06 Jan 2022 18:33:48 CST | Thu, 06 Jan 2022 18:33:50 CST |
| update-check |                | minikube | jim  | v1.22.0 | Thu, 06 Jan 2022 18:42:15 CST | Thu, 06 Jan 2022 18:42:17 CST |
| update-check |                | minikube | jim  | v1.22.0 | Thu, 06 Jan 2022 18:42:22 CST | Thu, 06 Jan 2022 18:42:22 CST |
| update-check |                | minikube | jim  | v1.22.0 | Thu, 06 Jan 2022 18:53:15 CST | Thu, 06 Jan 2022 18:53:17 CST |
| update-check |                | minikube | jim  | v1.22.0 | Sun, 16 Jan 2022 19:40:30 CST | Sun, 16 Jan 2022 19:40:31 CST |
| update-check |                | minikube | jim  | v1.22.0 | Sun, 16 Jan 2022 19:41:12 CST | Sun, 16 Jan 2022 19:41:14 CST |
| update-check |                | minikube | jim  | v1.22.0 | Sun, 16 Jan 2022 22:03:23 CST | Sun, 16 Jan 2022 22:03:24 CST |
| update-check |                | minikube | jim  | v1.22.0 | Sun, 16 Jan 2022 22:05:47 CST | Sun, 16 Jan 2022 22:05:47 CST |
| update-check |                | minikube | jim  | v1.22.0 | Wed, 19 Jan 2022 15:12:28 CST | Wed, 19 Jan 2022 15:12:29 CST |
| update-check |                | minikube | jim  | v1.22.0 | Tue, 25 Jan 2022 14:46:01 CST | Tue, 25 Jan 2022 14:46:08 CST |
| update-check |                | minikube | jim  | v1.22.0 | Tue, 25 Jan 2022 19:17:47 CST | Tue, 25 Jan 2022 19:17:48 CST |
| update-check |                | minikube | jim  | v1.22.0 | Tue, 25 Jan 2022 22:38:01 CST | Tue, 25 Jan 2022 22:38:05 CST |
| update-check |                | minikube | jim  | v1.22.0 | Tue, 25 Jan 2022 22:42:28 CST | Tue, 25 Jan 2022 22:42:34 CST |
| update-check |                | minikube | jim  | v1.22.0 | Tue, 25 Jan 2022 22:42:45 CST | Tue, 25 Jan 2022 22:42:48 CST |
| start        |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:02 CST           | 24 Apr 23 16:05 CST           |
| start        |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:05 CST           | 24 Apr 23 16:06 CST           |
| kubectl      | -- get po -A   | minikube | jim  | v1.29.0 | 24 Apr 23 16:06 CST           |                               |
| dashboard    |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:07 CST           |                               |
| ip           |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:11 CST           | 24 Apr 23 16:11 CST           |
| ip           |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:15 CST           | 24 Apr 23 16:15 CST           |
| ip           |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:33 CST           | 24 Apr 23 16:33 CST           |
| ip           |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:39 CST           | 24 Apr 23 16:39 CST           |
| ip           |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:46 CST           | 24 Apr 23 16:46 CST           |
| ip           |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:56 CST           | 24 Apr 23 16:56 CST           |
| ip           |                | minikube | jim  | v1.29.0 | 24 Apr 23 16:59 CST           | 24 Apr 23 16:59 CST           |
| addons       | enable ingress | minikube | jim  | v1.29.0 | 24 Apr 23 17:03 CST           |                               |
|--------------|----------------|----------|------|---------|-------------------------------|-------------------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/04/24 16:05:45
Running on machine: MacBook-Pro
Binary: Built with gc go1.19.5 for darwin/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0424 16:05:45.844026   78877 out.go:296] Setting OutFile to fd 1 ...
I0424 16:05:45.844278   78877 out.go:348] isatty.IsTerminal(1) = true
I0424 16:05:45.844288   78877 out.go:309] Setting ErrFile to fd 2...
I0424 16:05:45.844295   78877 out.go:348] isatty.IsTerminal(2) = true
I0424 16:05:45.844505   78877 root.go:334] Updating PATH: /Users/jim/.minikube/bin
W0424 16:05:45.844662   78877 root.go:311] Error reading config file at /Users/jim/.minikube/config/config.json: open /Users/jim/.minikube/config/config.json: no such file or directory
I0424 16:05:45.845167   78877 out.go:303] Setting JSON to false
I0424 16:05:45.903084   78877 start.go:125] hostinfo: {"hostname":"MacBook-Pro.local","uptime":1236347,"bootTime":1681087198,"procs":599,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"13.0.1","kernelVersion":"22.1.0","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"610dc803-991e-55c6-9698-9eec05765666"}
W0424 16:05:45.903220   78877 start.go:133] gopshost.Virtualization returned error: not implemented yet
I0424 16:05:45.922765   78877 out.go:177] üòÑ  Darwin 13.0.1 ‰∏äÁöÑ minikube v1.29.0
I0424 16:05:45.962389   78877 notify.go:220] Checking for updates...
I0424 16:05:45.963033   78877 config.go:180] Loaded profile config "minikube": Driver=hyperkit, ContainerRuntime=docker, KubernetesVersion=v1.22.3
I0424 16:05:45.981832   78877 out.go:177] üÜï  Kubernetes 1.26.1 is now available. If you would like to upgrade, specify: --kubernetes-version=v1.26.1
I0424 16:05:46.001921   78877 driver.go:365] Setting default libvirt URI to qemu:///system
I0424 16:05:46.002825   78877 main.go:141] libmachine: Found binary path at /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:05:46.002903   78877 main.go:141] libmachine: Launching plugin server for driver hyperkit
I0424 16:05:46.015103   78877 main.go:141] libmachine: Plugin server listening at address 127.0.0.1:64339
I0424 16:05:46.015812   78877 main.go:141] libmachine: () Calling .GetVersion
I0424 16:05:46.016627   78877 main.go:141] libmachine: Using API Version  1
I0424 16:05:46.016647   78877 main.go:141] libmachine: () Calling .SetConfigRaw
I0424 16:05:46.017072   78877 main.go:141] libmachine: () Calling .GetMachineName
I0424 16:05:46.017234   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:46.043836   78877 out.go:177] ‚ú®  Ê†πÊçÆÁé∞ÊúâÁöÑÈÖçÁΩÆÊñá‰ª∂‰ΩøÁî® hyperkit È©±Âä®Á®ãÂ∫è
I0424 16:05:46.079872   78877 start.go:296] selected driver: hyperkit
I0424 16:05:46.079886   78877 start.go:857] validating driver "hyperkit" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.29.0-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.28@sha256:4780f1897569d2bf77aafb3d133a08d42b4fe61127f06fcfc90c2c5d902d893c Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:hyperkit HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.64.2 Port:8443 KubernetesVersion:v1.22.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion: MountGID: MountIP: MountMSize:0 MountOptions:[] MountPort:0 MountType: MountUID: BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0424 16:05:46.080032   78877 start.go:868] status for hyperkit: {Installed:true Healthy:true Running:true NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0424 16:05:46.080123   78877 install.go:52] acquiring lock: {Name:mk4023283b30b374c3f04c8805d539e68824c0b8 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0424 16:05:46.080279   78877 install.go:117] Validating docker-machine-driver-hyperkit, PATH=/Users/jim/.minikube/bin:/usr/local/opt/mongodb-community@5.0/bin:/usr/local/sbin:/Users/jim/Workdata/goland/go1.16.15/bin:/Users/jim/Workdata/protobuf.dart-master/protoc_plugin/bin:/usr/local/opt/rabbitmq/sbin/:/Users/jim/Downloads/apache-maven-3.6.3/bin:/usr/local/opt/make/libexec/gnubin:/Users/jim/Downloads:/Users/jim/Workdata/goland/bin:/usr/local/opt/qt/bin:/usr/local/opt/openssl/bin:/Library/Java/JavaVirtualMachines/jdk1.8.0_321.jdk/Contents/Home/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion.app/Contents/Public:/usr/local/go/bin:/usr/local/share/dotnet:~/.dotnet/tools:/Library/Apple/usr/bin:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Users/jim/.rvm/bin::/usr/local/apache-jmeter-5.1.1/bin:/Users/jim/Workdata/EFAK/bin:/Users/jim/pear/bin:/Users/jim/.composer/vendor/bin:/Users/jim/Workdata/goland/bin:/Users/jim/Workdata/testphp/bin:/Users/jim/Downloads/apache-maven-3.6.3/bin:/Users/jim/.rvm/bin:/usr/local/Cellar/mongodb-community/4.4.3/bin:/usr/local/Cellar/erlang/24.0.3/bin:/usr/local/Cellar/rabbitmq/3.8.19/bin
I0424 16:05:46.091931   78877 install.go:137] /Users/jim/.minikube/bin/docker-machine-driver-hyperkit version is 1.24.0
I0424 16:05:46.101158   78877 install.go:79] stdout: /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:05:46.101181   78877 install.go:81] /Users/jim/.minikube/bin/docker-machine-driver-hyperkit looks good
I0424 16:05:46.101450   78877 cni.go:84] Creating CNI manager for ""
I0424 16:05:46.101468   78877 cni.go:161] CNI unnecessary in this configuration, recommending no CNI
I0424 16:05:46.101482   78877 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.29.0-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.28@sha256:4780f1897569d2bf77aafb3d133a08d42b4fe61127f06fcfc90c2c5d902d893c Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:hyperkit HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.64.2 Port:8443 KubernetesVersion:v1.22.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion: MountGID: MountIP: MountMSize:0 MountOptions:[] MountPort:0 MountType: MountUID: BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0424 16:05:46.101627   78877 iso.go:125] acquiring lock: {Name:mka390f0d72096dd69522522472375fb85eed239 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0424 16:05:46.140749   78877 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0424 16:05:46.158774   78877 preload.go:132] Checking if preload exists for k8s version v1.22.3 and runtime docker
I0424 16:05:46.158842   78877 preload.go:148] Found local preload: /Users/jim/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.22.3-docker-overlay2-amd64.tar.lz4
I0424 16:05:46.158861   78877 cache.go:57] Caching tarball of preloaded images
I0424 16:05:46.159013   78877 preload.go:174] Found /Users/jim/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.22.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0424 16:05:46.159024   78877 cache.go:60] Finished verifying existence of preloaded tar for  v1.22.3 on docker
I0424 16:05:46.159150   78877 profile.go:148] Saving config to /Users/jim/.minikube/profiles/minikube/config.json ...
I0424 16:05:46.159952   78877 cache.go:193] Successfully downloaded all kic artifacts
I0424 16:05:46.159992   78877 start.go:364] acquiring machines lock for minikube: {Name:mkf2b2ab0932a103d7f49894747f1983eb9228ac Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I0424 16:05:46.160072   78877 start.go:368] acquired machines lock for "minikube" in 67.619¬µs
I0424 16:05:46.160099   78877 start.go:96] Skipping create...Using existing machine configuration
I0424 16:05:46.160111   78877 fix.go:55] fixHost starting: 
I0424 16:05:46.160452   78877 main.go:141] libmachine: Found binary path at /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:05:46.160486   78877 main.go:141] libmachine: Launching plugin server for driver hyperkit
I0424 16:05:46.172047   78877 main.go:141] libmachine: Plugin server listening at address 127.0.0.1:64341
I0424 16:05:46.172642   78877 main.go:141] libmachine: () Calling .GetVersion
I0424 16:05:46.173174   78877 main.go:141] libmachine: Using API Version  1
I0424 16:05:46.173193   78877 main.go:141] libmachine: () Calling .SetConfigRaw
I0424 16:05:46.173555   78877 main.go:141] libmachine: () Calling .GetMachineName
I0424 16:05:46.173724   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:46.173876   78877 main.go:141] libmachine: (minikube) Calling .GetState
I0424 16:05:46.173998   78877 main.go:141] libmachine: (minikube) DBG | exe=/Users/jim/.minikube/bin/docker-machine-driver-hyperkit uid=0
I0424 16:05:46.174117   78877 main.go:141] libmachine: (minikube) DBG | hyperkit pid from json: 76920
I0424 16:05:46.176192   78877 fix.go:103] recreateIfNeeded on minikube: state=Running err=<nil>
W0424 16:05:46.176210   78877 fix.go:129] unexpected machine state, will restart: <nil>
I0424 16:05:46.196266   78877 out.go:177] üèÉ  Updating the running hyperkit "minikube" VM ...
I0424 16:05:46.235175   78877 machine.go:88] provisioning docker machine ...
I0424 16:05:46.235195   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:46.235430   78877 main.go:141] libmachine: (minikube) Calling .GetMachineName
I0424 16:05:46.235577   78877 buildroot.go:166] provisioning hostname "minikube"
I0424 16:05:46.235589   78877 main.go:141] libmachine: (minikube) Calling .GetMachineName
I0424 16:05:46.235754   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:46.235910   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:46.236044   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:46.236176   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:46.236289   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:46.237014   78877 main.go:141] libmachine: Using SSH client type: native
I0424 16:05:46.237309   78877 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1003f3a20] 0x1003f6ba0 <nil>  [] 0s} 192.168.64.2 22 <nil> <nil>}
I0424 16:05:46.237319   78877 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0424 16:05:46.373546   78877 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0424 16:05:46.373589   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:46.373798   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:46.373920   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:46.374068   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:46.374179   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:46.374535   78877 main.go:141] libmachine: Using SSH client type: native
I0424 16:05:46.374743   78877 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1003f3a20] 0x1003f6ba0 <nil>  [] 0s} 192.168.64.2 22 <nil> <nil>}
I0424 16:05:46.374762   78877 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0424 16:05:46.483177   78877 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0424 16:05:46.483196   78877 buildroot.go:172] set auth options {CertDir:/Users/jim/.minikube CaCertPath:/Users/jim/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/jim/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/jim/.minikube/machines/server.pem ServerKeyPath:/Users/jim/.minikube/machines/server-key.pem ClientKeyPath:/Users/jim/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/jim/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/jim/.minikube}
I0424 16:05:46.483218   78877 buildroot.go:174] setting up certificates
I0424 16:05:46.483231   78877 provision.go:83] configureAuth start
I0424 16:05:46.483240   78877 main.go:141] libmachine: (minikube) Calling .GetMachineName
I0424 16:05:46.483436   78877 main.go:141] libmachine: (minikube) Calling .GetIP
I0424 16:05:46.483583   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:46.483699   78877 provision.go:138] copyHostCerts
I0424 16:05:46.483825   78877 exec_runner.go:144] found /Users/jim/.minikube/cert.pem, removing ...
I0424 16:05:46.483835   78877 exec_runner.go:207] rm: /Users/jim/.minikube/cert.pem
I0424 16:05:46.484071   78877 exec_runner.go:151] cp: /Users/jim/.minikube/certs/cert.pem --> /Users/jim/.minikube/cert.pem (1111 bytes)
I0424 16:05:46.485257   78877 exec_runner.go:144] found /Users/jim/.minikube/key.pem, removing ...
I0424 16:05:46.485264   78877 exec_runner.go:207] rm: /Users/jim/.minikube/key.pem
I0424 16:05:46.485390   78877 exec_runner.go:151] cp: /Users/jim/.minikube/certs/key.pem --> /Users/jim/.minikube/key.pem (1679 bytes)
I0424 16:05:46.485912   78877 exec_runner.go:144] found /Users/jim/.minikube/ca.pem, removing ...
I0424 16:05:46.485918   78877 exec_runner.go:207] rm: /Users/jim/.minikube/ca.pem
I0424 16:05:46.486099   78877 exec_runner.go:151] cp: /Users/jim/.minikube/certs/ca.pem --> /Users/jim/.minikube/ca.pem (1070 bytes)
I0424 16:05:46.486538   78877 provision.go:112] generating server cert: /Users/jim/.minikube/machines/server.pem ca-key=/Users/jim/.minikube/certs/ca.pem private-key=/Users/jim/.minikube/certs/ca-key.pem org=jim.minikube san=[192.168.64.2 192.168.64.2 localhost 127.0.0.1 minikube minikube]
I0424 16:05:46.744507   78877 provision.go:172] copyRemoteCerts
I0424 16:05:46.744741   78877 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0424 16:05:46.744758   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:46.744953   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:46.745095   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:46.745238   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:46.745374   78877 sshutil.go:53] new ssh client: &{IP:192.168.64.2 Port:22 SSHKeyPath:/Users/jim/.minikube/machines/minikube/id_rsa Username:docker}
I0424 16:05:46.811186   78877 ssh_runner.go:362] scp /Users/jim/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1070 bytes)
I0424 16:05:46.854158   78877 ssh_runner.go:362] scp /Users/jim/.minikube/machines/server.pem --> /etc/docker/server.pem (1192 bytes)
I0424 16:05:46.899242   78877 ssh_runner.go:362] scp /Users/jim/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0424 16:05:46.944617   78877 provision.go:86] duration metric: configureAuth took 461.356226ms
I0424 16:05:46.944629   78877 buildroot.go:189] setting minikube options for container-runtime
I0424 16:05:46.944822   78877 config.go:180] Loaded profile config "minikube": Driver=hyperkit, ContainerRuntime=docker, KubernetesVersion=v1.22.3
I0424 16:05:46.944836   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:46.945019   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:46.945149   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:46.945298   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:46.945433   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:46.945560   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:46.945943   78877 main.go:141] libmachine: Using SSH client type: native
I0424 16:05:46.946140   78877 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1003f3a20] 0x1003f6ba0 <nil>  [] 0s} 192.168.64.2 22 <nil> <nil>}
I0424 16:05:46.946148   78877 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0424 16:05:47.058189   78877 main.go:141] libmachine: SSH cmd err, output: <nil>: tmpfs

I0424 16:05:47.058202   78877 buildroot.go:70] root file system type: tmpfs
I0424 16:05:47.058395   78877 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0424 16:05:47.058418   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:47.058628   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:47.058798   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.058948   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.059080   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:47.059437   78877 main.go:141] libmachine: Using SSH client type: native
I0424 16:05:47.059609   78877 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1003f3a20] 0x1003f6ba0 <nil>  [] 0s} 192.168.64.2 22 <nil> <nil>}
I0424 16:05:47.059683   78877 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=hyperkit --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0424 16:05:47.187172   78877 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=hyperkit --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0424 16:05:47.187198   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:47.187385   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:47.187524   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.187697   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.187829   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:47.188169   78877 main.go:141] libmachine: Using SSH client type: native
I0424 16:05:47.188334   78877 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1003f3a20] 0x1003f6ba0 <nil>  [] 0s} 192.168.64.2 22 <nil> <nil>}
I0424 16:05:47.188350   78877 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0424 16:05:47.317509   78877 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0424 16:05:47.317533   78877 machine.go:91] provisioned docker machine in 1.082316706s
I0424 16:05:47.317540   78877 start.go:300] post-start starting for "minikube" (driver="hyperkit")
I0424 16:05:47.317549   78877 start.go:328] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0424 16:05:47.317570   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:47.318019   78877 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0424 16:05:47.318034   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:47.318190   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:47.318340   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.318464   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:47.318598   78877 sshutil.go:53] new ssh client: &{IP:192.168.64.2 Port:22 SSHKeyPath:/Users/jim/.minikube/machines/minikube/id_rsa Username:docker}
I0424 16:05:47.384716   78877 ssh_runner.go:195] Run: cat /etc/os-release
I0424 16:05:47.390910   78877 info.go:137] Remote host: Buildroot 2021.02.12
I0424 16:05:47.390930   78877 filesync.go:126] Scanning /Users/jim/.minikube/addons for local assets ...
I0424 16:05:47.391111   78877 filesync.go:126] Scanning /Users/jim/.minikube/files for local assets ...
I0424 16:05:47.391215   78877 start.go:303] post-start completed in 73.663712ms
I0424 16:05:47.391227   78877 fix.go:57] fixHost completed within 1.231085322s
I0424 16:05:47.391248   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:47.391480   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:47.391649   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.391808   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.391999   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:47.392392   78877 main.go:141] libmachine: Using SSH client type: native
I0424 16:05:47.392544   78877 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1003f3a20] 0x1003f6ba0 <nil>  [] 0s} 192.168.64.2 22 <nil> <nil>}
I0424 16:05:47.392551   78877 main.go:141] libmachine: About to run SSH command:
date +%!s(MISSING).%!N(MISSING)
I0424 16:05:47.502298   78877 main.go:141] libmachine: SSH cmd err, output: <nil>: 1682323547.787322850

I0424 16:05:47.502307   78877 fix.go:207] guest clock: 1682323547.787322850
I0424 16:05:47.502313   78877 fix.go:220] Guest: 2023-04-24 16:05:47.78732285 +0800 CST Remote: 2023-04-24 16:05:47.391229 +0800 CST m=+1.628195718 (delta=396.09385ms)
I0424 16:05:47.502343   78877 fix.go:191] guest clock delta is within tolerance: 396.09385ms
I0424 16:05:47.502347   78877 start.go:83] releasing machines lock for "minikube", held for 1.342229117s
I0424 16:05:47.502369   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:47.502570   78877 main.go:141] libmachine: (minikube) Calling .GetIP
I0424 16:05:47.502729   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:47.503433   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:47.503609   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:05:47.504211   78877 ssh_runner.go:195] Run: cat /version.json
I0424 16:05:47.504226   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:47.504376   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:47.504514   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.504662   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:47.504794   78877 ssh_runner.go:195] Run: curl -sS -m 2 https://k8s.gcr.io/
I0424 16:05:47.504834   78877 sshutil.go:53] new ssh client: &{IP:192.168.64.2 Port:22 SSHKeyPath:/Users/jim/.minikube/machines/minikube/id_rsa Username:docker}
I0424 16:05:47.504844   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:05:47.505047   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:05:47.505233   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:05:47.505403   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:05:47.505620   78877 sshutil.go:53] new ssh client: &{IP:192.168.64.2 Port:22 SSHKeyPath:/Users/jim/.minikube/machines/minikube/id_rsa Username:docker}
I0424 16:05:47.562255   78877 ssh_runner.go:195] Run: systemctl --version
I0424 16:05:47.572369   78877 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0424 16:05:49.588490   78877 ssh_runner.go:235] Completed: curl -sS -m 2 https://k8s.gcr.io/: (2.083613116s)
W0424 16:05:49.588522   78877 start.go:833] [curl -sS -m 2 https://k8s.gcr.io/] failed: curl -sS -m 2 https://k8s.gcr.io/: Process exited with status 28
stdout:

stderr:
curl: (28) Connection timed out after 2000 milliseconds
I0424 16:05:49.588539   78877 ssh_runner.go:235] Completed: sh -c "stat /etc/cni/net.d/*loopback.conf*": (2.016095402s)
W0424 16:05:49.588562   78877 cni.go:208] loopback cni configuration skipped: "/etc/cni/net.d/*loopback.conf*" not found
W0424 16:05:49.588634   78877 out.go:239] ‚ùó  This VM is having trouble accessing https://k8s.gcr.io
W0424 16:05:49.588656   78877 out.go:239] üí°  To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
I0424 16:05:49.588814   78877 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *bridge* -not -name *podman* -not -name *.mk_disabled -printf "%!p(MISSING), " -exec sh -c "sudo sed -i -r -e '/"dst": ".*:.*"/d' -e 's|^(.*)"dst": (.*)[,*]$|\1"dst": \2|g' -e '/"subnet": ".*:.*"/d' -e 's|^(.*)"subnet": ".*"(.*)[,*]$|\1"subnet": "10.244.0.0/16"\2|g' {}" ;
I0424 16:05:49.606848   78877 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *podman* -not -name *.mk_disabled -printf "%!p(MISSING), " -exec sh -c "sudo sed -i -r -e 's|^(.*)"subnet": ".*"(.*)$|\1"subnet": "10.244.0.0/16"\2|g' -e 's|^(.*)"gateway": ".*"(.*)$|\1"gateway": "10.244.0.1"\2|g' {}" ;
I0424 16:05:49.636319   78877 cni.go:307] configured [/etc/cni/net.d/87-podman-bridge.conflist] bridge cni config(s)
I0424 16:05:49.636333   78877 preload.go:132] Checking if preload exists for k8s version v1.22.3 and runtime docker
I0424 16:05:49.636606   78877 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0424 16:05:49.682648   78877 docker.go:630] Got preloaded images: -- stdout --
k8s.gcr.io/kube-apiserver:v1.22.3
k8s.gcr.io/kube-scheduler:v1.22.3
k8s.gcr.io/kube-controller-manager:v1.22.3
k8s.gcr.io/kube-proxy:v1.22.3
k8s.gcr.io/etcd:3.5.0-0
k8s.gcr.io/coredns/coredns:v1.8.4
gcr.io/k8s-minikube/storage-provisioner:v5
k8s.gcr.io/pause:3.5

-- /stdout --
I0424 16:05:49.682668   78877 docker.go:560] Images already preloaded, skipping extraction
I0424 16:05:49.682677   78877 start.go:483] detecting cgroup driver to use...
I0424 16:05:49.682791   78877 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0424 16:05:49.715626   78877 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "k8s.gcr.io/pause:3.5"|' /etc/containerd/config.toml"
I0424 16:05:49.733728   78877 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0424 16:05:49.754905   78877 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0424 16:05:49.755156   78877 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0424 16:05:49.782941   78877 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0424 16:05:49.801188   78877 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0424 16:05:49.818570   78877 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0424 16:05:49.836960   78877 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0424 16:05:49.859010   78877 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0424 16:05:49.884142   78877 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0424 16:05:49.901446   78877 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0424 16:05:49.919076   78877 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0424 16:05:50.229936   78877 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0424 16:05:50.270000   78877 start.go:483] detecting cgroup driver to use...
I0424 16:05:50.270267   78877 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0424 16:05:50.296801   78877 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0424 16:05:50.329763   78877 ssh_runner.go:195] Run: sudo systemctl stop -f containerd
I0424 16:05:50.371507   78877 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0424 16:05:50.394338   78877 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0424 16:05:50.416745   78877 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/dockershim.sock
image-endpoint: unix:///var/run/dockershim.sock
" | sudo tee /etc/crictl.yaml"
I0424 16:05:50.447575   78877 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0424 16:05:50.747222   78877 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0424 16:05:51.052089   78877 docker.go:529] configuring docker to use "cgroupfs" as cgroup driver...
I0424 16:05:51.052127   78877 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I0424 16:05:51.082400   78877 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0424 16:05:51.351080   78877 ssh_runner.go:195] Run: sudo systemctl restart docker
W0424 16:06:00.398090   78877 notify.go:59] Error getting json from minikube version url: error with http GET for endpoint https://storage.googleapis.com/minikube/releases-v2.json: Get "https://storage.googleapis.com/minikube/releases-v2.json": unexpected EOF
I0424 16:06:09.452657   78877 ssh_runner.go:235] Completed: sudo systemctl restart docker: (18.101007147s)
I0424 16:06:09.452891   78877 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0424 16:06:09.544170   78877 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0424 16:06:09.614938   78877 out.go:204] üê≥  Ê≠£Âú® Docker 20.10.23 ‰∏≠ÂáÜÂ§á Kubernetes v1.22.3‚Ä¶
I0424 16:06:09.615686   78877 ssh_runner.go:195] Run: grep 192.168.64.1	host.minikube.internal$ /etc/hosts
I0424 16:06:09.622318   78877 preload.go:132] Checking if preload exists for k8s version v1.22.3 and runtime docker
I0424 16:06:09.622546   78877 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0424 16:06:09.661198   78877 docker.go:630] Got preloaded images: -- stdout --
k8s.gcr.io/kube-apiserver:v1.22.3
k8s.gcr.io/kube-controller-manager:v1.22.3
k8s.gcr.io/kube-scheduler:v1.22.3
k8s.gcr.io/kube-proxy:v1.22.3
k8s.gcr.io/etcd:3.5.0-0
k8s.gcr.io/coredns/coredns:v1.8.4
gcr.io/k8s-minikube/storage-provisioner:v5
k8s.gcr.io/pause:3.5

-- /stdout --
I0424 16:06:09.661212   78877 docker.go:560] Images already preloaded, skipping extraction
I0424 16:06:09.661426   78877 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0424 16:06:09.700313   78877 docker.go:630] Got preloaded images: -- stdout --
k8s.gcr.io/kube-apiserver:v1.22.3
k8s.gcr.io/kube-controller-manager:v1.22.3
k8s.gcr.io/kube-scheduler:v1.22.3
k8s.gcr.io/kube-proxy:v1.22.3
k8s.gcr.io/etcd:3.5.0-0
k8s.gcr.io/coredns/coredns:v1.8.4
gcr.io/k8s-minikube/storage-provisioner:v5
k8s.gcr.io/pause:3.5

-- /stdout --
I0424 16:06:09.700333   78877 cache_images.go:84] Images are preloaded, skipping loading
I0424 16:06:09.700550   78877 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0424 16:06:09.759466   78877 cni.go:84] Creating CNI manager for ""
I0424 16:06:09.759485   78877 cni.go:161] CNI unnecessary in this configuration, recommending no CNI
I0424 16:06:09.759510   78877 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0424 16:06:09.759530   78877 kubeadm.go:172] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.64.2 APIServerPort:8443 KubernetesVersion:v1.22.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/dockershim.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.64.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.64.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m]}
I0424 16:06:09.759675   78877 kubeadm.go:177] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.64.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.64.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.64.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.22.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0424 16:06:09.759765   78877 kubeadm.go:968] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.22.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=docker --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.64.2

[Install]
 config:
{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0424 16:06:09.759997   78877 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.22.3
I0424 16:06:09.776823   78877 binaries.go:44] Found k8s binaries, skipping transfer
I0424 16:06:09.777056   78877 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0424 16:06:09.792198   78877 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (334 bytes)
I0424 16:06:09.820106   78877 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0424 16:06:09.848457   78877 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2104 bytes)
I0424 16:06:09.877490   78877 ssh_runner.go:195] Run: grep 192.168.64.2	control-plane.minikube.internal$ /etc/hosts
I0424 16:06:09.883135   78877 certs.go:56] Setting up /Users/jim/.minikube/profiles/minikube for IP: 192.168.64.2
I0424 16:06:09.883154   78877 certs.go:186] acquiring lock for shared ca certs: {Name:mk741236379b839d7b8014c2fbe5005d0191af66 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0424 16:06:09.883427   78877 certs.go:195] skipping minikubeCA CA generation: /Users/jim/.minikube/ca.key
I0424 16:06:09.884350   78877 certs.go:195] skipping proxyClientCA CA generation: /Users/jim/.minikube/proxy-client-ca.key
I0424 16:06:09.884485   78877 certs.go:311] skipping minikube-user signed cert generation: /Users/jim/.minikube/profiles/minikube/client.key
I0424 16:06:09.884858   78877 certs.go:311] skipping minikube signed cert generation: /Users/jim/.minikube/profiles/minikube/apiserver.key.a30f3483
I0424 16:06:09.885083   78877 certs.go:311] skipping aggregator signed cert generation: /Users/jim/.minikube/profiles/minikube/proxy-client.key
I0424 16:06:09.885426   78877 certs.go:401] found cert: /Users/jim/.minikube/certs/Users/jim/.minikube/certs/ca-key.pem (1675 bytes)
I0424 16:06:09.885481   78877 certs.go:401] found cert: /Users/jim/.minikube/certs/Users/jim/.minikube/certs/ca.pem (1070 bytes)
I0424 16:06:09.885528   78877 certs.go:401] found cert: /Users/jim/.minikube/certs/Users/jim/.minikube/certs/cert.pem (1111 bytes)
I0424 16:06:09.885572   78877 certs.go:401] found cert: /Users/jim/.minikube/certs/Users/jim/.minikube/certs/key.pem (1679 bytes)
I0424 16:06:09.886256   78877 ssh_runner.go:362] scp /Users/jim/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0424 16:06:09.926532   78877 ssh_runner.go:362] scp /Users/jim/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0424 16:06:09.968516   78877 ssh_runner.go:362] scp /Users/jim/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0424 16:06:10.008835   78877 ssh_runner.go:362] scp /Users/jim/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0424 16:06:10.051066   78877 ssh_runner.go:362] scp /Users/jim/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0424 16:06:10.091401   78877 ssh_runner.go:362] scp /Users/jim/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0424 16:06:10.132471   78877 ssh_runner.go:362] scp /Users/jim/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0424 16:06:10.175074   78877 ssh_runner.go:362] scp /Users/jim/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0424 16:06:10.215584   78877 ssh_runner.go:362] scp /Users/jim/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0424 16:06:10.258922   78877 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0424 16:06:10.287459   78877 ssh_runner.go:195] Run: openssl version
I0424 16:06:10.297600   78877 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0424 16:06:10.316219   78877 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0424 16:06:10.323945   78877 certs.go:444] hashing: -rw-r--r-- 1 root root 1111 Apr 24 08:04 /usr/share/ca-certificates/minikubeCA.pem
I0424 16:06:10.324107   78877 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0424 16:06:10.334165   78877 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0424 16:06:10.350154   78877 kubeadm.go:401] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.29.0-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.28@sha256:4780f1897569d2bf77aafb3d133a08d42b4fe61127f06fcfc90c2c5d902d893c Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:hyperkit HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.64.2 Port:8443 KubernetesVersion:v1.22.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion: MountGID: MountIP: MountMSize:0 MountOptions:[] MountPort:0 MountType: MountUID: BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0424 16:06:10.350427   78877 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0424 16:06:10.386972   78877 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0424 16:06:10.402330   78877 kubeadm.go:416] found existing configuration files, will attempt cluster restart
I0424 16:06:10.402346   78877 kubeadm.go:633] restartCluster start
I0424 16:06:10.402565   78877 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0424 16:06:10.417623   78877 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0424 16:06:10.418524   78877 kubeconfig.go:92] found "minikube" server: "https://192.168.64.2:8443"
I0424 16:06:10.420692   78877 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0424 16:06:10.435673   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:10.435965   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:10.456212   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:10.956619   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:10.956854   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:10.976775   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:11.456732   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:11.457007   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:11.477244   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:11.957199   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:11.957461   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:11.978137   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:12.456394   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:12.456691   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:12.509705   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:12.957087   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:12.957333   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:12.995201   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:13.456450   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:13.456715   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:13.498648   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:13.956405   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:13.956729   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:14.003841   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:14.456493   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:14.456829   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:14.509511   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:14.956482   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:14.956789   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:15.035436   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:15.457465   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:15.457707   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0424 16:06:15.490461   78877 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0424 16:06:15.957437   78877 api_server.go:165] Checking apiserver status ...
I0424 16:06:15.957682   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0424 16:06:16.028135   78877 ssh_runner.go:195] Run: sudo egrep ^[0-9]+:freezer: /proc/5473/cgroup
I0424 16:06:16.083326   78877 api_server.go:181] apiserver freezer: "8:freezer:/kubepods/burstable/podff345fe0a48dbde07a37558c2188538d/529b541d3e6941451c3f4a891c508d6feed14074105bff3f1a0fd80b1616195c"
I0424 16:06:16.083561   78877 ssh_runner.go:195] Run: sudo cat /sys/fs/cgroup/freezer/kubepods/burstable/podff345fe0a48dbde07a37558c2188538d/529b541d3e6941451c3f4a891c508d6feed14074105bff3f1a0fd80b1616195c/freezer.state
I0424 16:06:16.137072   78877 api_server.go:203] freezer state: "THAWED"
I0424 16:06:16.137091   78877 api_server.go:252] Checking apiserver healthz at https://192.168.64.2:8443/healthz ...
I0424 16:06:21.137609   78877 api_server.go:268] stopped: https://192.168.64.2:8443/healthz: Get "https://192.168.64.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0424 16:06:21.137661   78877 retry.go:31] will retry after 263.082536ms: state is "Stopped"
I0424 16:06:21.401629   78877 api_server.go:252] Checking apiserver healthz at https://192.168.64.2:8443/healthz ...
I0424 16:06:26.288267   78877 api_server.go:278] https://192.168.64.2:8443/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0424 16:06:26.288288   78877 retry.go:31] will retry after 381.329545ms: https://192.168.64.2:8443/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0424 16:06:26.670596   78877 api_server.go:252] Checking apiserver healthz at https://192.168.64.2:8443/healthz ...
I0424 16:06:26.698844   78877 api_server.go:278] https://192.168.64.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
healthz check failed
I0424 16:06:26.698864   78877 retry.go:31] will retry after 422.765636ms: https://192.168.64.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
healthz check failed
I0424 16:06:27.121773   78877 api_server.go:252] Checking apiserver healthz at https://192.168.64.2:8443/healthz ...
I0424 16:06:27.132865   78877 api_server.go:278] https://192.168.64.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
healthz check failed
I0424 16:06:27.132882   78877 retry.go:31] will retry after 473.074753ms: https://192.168.64.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
healthz check failed
I0424 16:06:27.607026   78877 api_server.go:252] Checking apiserver healthz at https://192.168.64.2:8443/healthz ...
I0424 16:06:27.620724   78877 api_server.go:278] https://192.168.64.2:8443/healthz returned 200:
ok
I0424 16:06:27.642333   78877 system_pods.go:86] 7 kube-system pods found
I0424 16:06:27.642349   78877 system_pods.go:89] "coredns-78fcd69978-6j56x" [5a9da0ea-b3a1-4544-ba26-7707cb60cdc5] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0424 16:06:27.642362   78877 system_pods.go:89] "etcd-minikube" [825f1a20-68da-4e4d-883b-225ab8534d1e] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I0424 16:06:27.642368   78877 system_pods.go:89] "kube-apiserver-minikube" [f070dd31-a935-4480-9079-5b985784e3aa] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0424 16:06:27.642374   78877 system_pods.go:89] "kube-controller-manager-minikube" [4a105009-c056-4383-912e-7c5f5fde2933] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0424 16:06:27.642378   78877 system_pods.go:89] "kube-proxy-rd9vt" [d3e3adac-030f-4cd0-ae91-9e059edd4dd5] Running
I0424 16:06:27.642383   78877 system_pods.go:89] "kube-scheduler-minikube" [0ea2ffe3-7a4d-4ec2-941b-1ec5159e60d6] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I0424 16:06:27.642387   78877 system_pods.go:89] "storage-provisioner" [c48d570e-6ed2-4efe-a2a4-005b2ce422b5] Running
I0424 16:06:27.643894   78877 api_server.go:140] control plane version: v1.22.3
I0424 16:06:27.643903   78877 kubeadm.go:627] The running cluster does not require reconfiguration: 192.168.64.2
I0424 16:06:27.643916   78877 kubeadm.go:681] Taking a shortcut, as the cluster seems to be properly configured
I0424 16:06:27.643922   78877 kubeadm.go:637] restartCluster took 17.241054845s
I0424 16:06:27.643926   78877 kubeadm.go:403] StartCluster complete in 17.293266428s
I0424 16:06:27.643938   78877 settings.go:142] acquiring lock: {Name:mk356e2fb0b26aeebe066b18348f9391f04f0e22 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0424 16:06:27.644043   78877 settings.go:150] Updating kubeconfig:  /Users/jim/.kube/config
I0424 16:06:27.645249   78877 lock.go:35] WriteFile acquiring /Users/jim/.kube/config: {Name:mk5c080e8b2ee1a6951eb1dc664cef2e073f4177 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0424 16:06:27.645641   78877 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.22.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0424 16:06:27.645727   78877 addons.go:489] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false]
I0424 16:06:27.645815   78877 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I0424 16:06:27.645826   78877 addons.go:65] Setting default-storageclass=true in profile "minikube"
I0424 16:06:27.645833   78877 addons.go:227] Setting addon storage-provisioner=true in "minikube"
W0424 16:06:27.645839   78877 addons.go:236] addon storage-provisioner should already be in state true
I0424 16:06:27.645845   78877 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0424 16:06:27.645869   78877 config.go:180] Loaded profile config "minikube": Driver=hyperkit, ContainerRuntime=docker, KubernetesVersion=v1.22.3
I0424 16:06:27.645884   78877 host.go:66] Checking if "minikube" exists ...
I0424 16:06:27.646245   78877 main.go:141] libmachine: Found binary path at /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:06:27.646267   78877 main.go:141] libmachine: Launching plugin server for driver hyperkit
I0424 16:06:27.646286   78877 main.go:141] libmachine: Found binary path at /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:06:27.646314   78877 main.go:141] libmachine: Launching plugin server for driver hyperkit
I0424 16:06:27.657706   78877 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0424 16:06:27.657741   78877 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.64.2 Port:8443 KubernetesVersion:v1.22.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0424 16:06:27.658923   78877 main.go:141] libmachine: Plugin server listening at address 127.0.0.1:64408
I0424 16:06:27.660268   78877 main.go:141] libmachine: Plugin server listening at address 127.0.0.1:64409
I0424 16:06:27.678367   78877 out.go:177] üîé  Verifying Kubernetes components...
I0424 16:06:27.679210   78877 main.go:141] libmachine: () Calling .GetVersion
I0424 16:06:27.679298   78877 main.go:141] libmachine: () Calling .GetVersion
I0424 16:06:27.697920   78877 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0424 16:06:27.698303   78877 main.go:141] libmachine: Using API Version  1
I0424 16:06:27.698325   78877 main.go:141] libmachine: () Calling .SetConfigRaw
I0424 16:06:27.698403   78877 main.go:141] libmachine: Using API Version  1
I0424 16:06:27.698431   78877 main.go:141] libmachine: () Calling .SetConfigRaw
I0424 16:06:27.698750   78877 main.go:141] libmachine: () Calling .GetMachineName
I0424 16:06:27.698873   78877 main.go:141] libmachine: () Calling .GetMachineName
I0424 16:06:27.699007   78877 main.go:141] libmachine: (minikube) Calling .GetState
I0424 16:06:27.699165   78877 main.go:141] libmachine: (minikube) DBG | exe=/Users/jim/.minikube/bin/docker-machine-driver-hyperkit uid=0
I0424 16:06:27.699292   78877 main.go:141] libmachine: (minikube) DBG | hyperkit pid from json: 76920
I0424 16:06:27.699574   78877 main.go:141] libmachine: Found binary path at /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:06:27.699620   78877 main.go:141] libmachine: Launching plugin server for driver hyperkit
I0424 16:06:27.711752   78877 main.go:141] libmachine: Plugin server listening at address 127.0.0.1:64412
I0424 16:06:27.712344   78877 main.go:141] libmachine: () Calling .GetVersion
I0424 16:06:27.712876   78877 main.go:141] libmachine: Using API Version  1
I0424 16:06:27.712894   78877 main.go:141] libmachine: () Calling .SetConfigRaw
I0424 16:06:27.713198   78877 main.go:141] libmachine: () Calling .GetMachineName
I0424 16:06:27.713363   78877 main.go:141] libmachine: (minikube) Calling .GetState
I0424 16:06:27.713468   78877 main.go:141] libmachine: (minikube) DBG | exe=/Users/jim/.minikube/bin/docker-machine-driver-hyperkit uid=0
I0424 16:06:27.713595   78877 main.go:141] libmachine: (minikube) DBG | hyperkit pid from json: 76920
I0424 16:06:27.714756   78877 addons.go:227] Setting addon default-storageclass=true in "minikube"
W0424 16:06:27.714763   78877 addons.go:236] addon default-storageclass should already be in state true
I0424 16:06:27.714785   78877 host.go:66] Checking if "minikube" exists ...
I0424 16:06:27.715155   78877 main.go:141] libmachine: Found binary path at /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:06:27.715185   78877 main.go:141] libmachine: Launching plugin server for driver hyperkit
I0424 16:06:27.716293   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:06:27.727836   78877 main.go:141] libmachine: Plugin server listening at address 127.0.0.1:64414
I0424 16:06:27.752464   78877 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0424 16:06:27.753238   78877 main.go:141] libmachine: () Calling .GetVersion
I0424 16:06:27.773062   78877 addons.go:419] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0424 16:06:27.773073   78877 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0424 16:06:27.773089   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:06:27.773323   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:06:27.773560   78877 main.go:141] libmachine: Using API Version  1
I0424 16:06:27.773575   78877 main.go:141] libmachine: () Calling .SetConfigRaw
I0424 16:06:27.773592   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:06:27.773804   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:06:27.773937   78877 main.go:141] libmachine: () Calling .GetMachineName
I0424 16:06:27.773978   78877 sshutil.go:53] new ssh client: &{IP:192.168.64.2 Port:22 SSHKeyPath:/Users/jim/.minikube/machines/minikube/id_rsa Username:docker}
I0424 16:06:27.774502   78877 main.go:141] libmachine: Found binary path at /Users/jim/.minikube/bin/docker-machine-driver-hyperkit
I0424 16:06:27.774534   78877 main.go:141] libmachine: Launching plugin server for driver hyperkit
I0424 16:06:27.786782   78877 main.go:141] libmachine: Plugin server listening at address 127.0.0.1:64417
I0424 16:06:27.787383   78877 main.go:141] libmachine: () Calling .GetVersion
I0424 16:06:27.787920   78877 main.go:141] libmachine: Using API Version  1
I0424 16:06:27.787937   78877 main.go:141] libmachine: () Calling .SetConfigRaw
I0424 16:06:27.788295   78877 main.go:141] libmachine: () Calling .GetMachineName
I0424 16:06:27.788446   78877 main.go:141] libmachine: (minikube) Calling .GetState
I0424 16:06:27.788582   78877 main.go:141] libmachine: (minikube) DBG | exe=/Users/jim/.minikube/bin/docker-machine-driver-hyperkit uid=0
I0424 16:06:27.788700   78877 main.go:141] libmachine: (minikube) DBG | hyperkit pid from json: 76920
I0424 16:06:27.790740   78877 main.go:141] libmachine: (minikube) Calling .DriverName
I0424 16:06:27.790978   78877 addons.go:419] installing /etc/kubernetes/addons/storageclass.yaml
I0424 16:06:27.790985   78877 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0424 16:06:27.790996   78877 main.go:141] libmachine: (minikube) Calling .GetSSHHostname
I0424 16:06:27.791116   78877 main.go:141] libmachine: (minikube) Calling .GetSSHPort
I0424 16:06:27.791240   78877 main.go:141] libmachine: (minikube) Calling .GetSSHKeyPath
I0424 16:06:27.791368   78877 main.go:141] libmachine: (minikube) Calling .GetSSHUsername
I0424 16:06:27.791501   78877 sshutil.go:53] new ssh client: &{IP:192.168.64.2 Port:22 SSHKeyPath:/Users/jim/.minikube/machines/minikube/id_rsa Username:docker}
I0424 16:06:27.836071   78877 api_server.go:51] waiting for apiserver process to appear ...
I0424 16:06:27.836292   78877 start.go:892] CoreDNS already contains "host.minikube.internal" host record, skipping...
I0424 16:06:27.836337   78877 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0424 16:06:27.893860   78877 api_server.go:71] duration metric: took 236.074789ms to wait for apiserver process to appear ...
I0424 16:06:27.893873   78877 api_server.go:87] waiting for apiserver healthz status ...
I0424 16:06:27.893883   78877 api_server.go:252] Checking apiserver healthz at https://192.168.64.2:8443/healthz ...
I0424 16:06:27.903718   78877 api_server.go:278] https://192.168.64.2:8443/healthz returned 200:
ok
I0424 16:06:27.904881   78877 api_server.go:140] control plane version: v1.22.3
I0424 16:06:27.904889   78877 api_server.go:130] duration metric: took 11.010993ms to wait for apiserver health ...
I0424 16:06:27.904898   78877 system_pods.go:43] waiting for kube-system pods to appear ...
I0424 16:06:27.913443   78877 system_pods.go:59] 7 kube-system pods found
I0424 16:06:27.913463   78877 system_pods.go:61] "coredns-78fcd69978-6j56x" [5a9da0ea-b3a1-4544-ba26-7707cb60cdc5] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0424 16:06:27.913473   78877 system_pods.go:61] "etcd-minikube" [825f1a20-68da-4e4d-883b-225ab8534d1e] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I0424 16:06:27.913479   78877 system_pods.go:61] "kube-apiserver-minikube" [f070dd31-a935-4480-9079-5b985784e3aa] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0424 16:06:27.913487   78877 system_pods.go:61] "kube-controller-manager-minikube" [4a105009-c056-4383-912e-7c5f5fde2933] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0424 16:06:27.913491   78877 system_pods.go:61] "kube-proxy-rd9vt" [d3e3adac-030f-4cd0-ae91-9e059edd4dd5] Running
I0424 16:06:27.913496   78877 system_pods.go:61] "kube-scheduler-minikube" [0ea2ffe3-7a4d-4ec2-941b-1ec5159e60d6] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I0424 16:06:27.913500   78877 system_pods.go:61] "storage-provisioner" [c48d570e-6ed2-4efe-a2a4-005b2ce422b5] Running
I0424 16:06:27.913504   78877 system_pods.go:74] duration metric: took 8.602966ms to wait for pod list to return data ...
I0424 16:06:27.913511   78877 kubeadm.go:578] duration metric: took 255.737103ms to wait for : map[apiserver:true system_pods:true] ...
I0424 16:06:27.913520   78877 node_conditions.go:102] verifying NodePressure condition ...
I0424 16:06:27.919174   78877 node_conditions.go:122] node storage ephemeral capacity is 17784752Ki
I0424 16:06:27.919194   78877 node_conditions.go:123] node cpu capacity is 2
I0424 16:06:27.919206   78877 node_conditions.go:105] duration metric: took 5.68258ms to run NodePressure ...
I0424 16:06:27.919216   78877 start.go:228] waiting for startup goroutines ...
I0424 16:06:27.934979   78877 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.22.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0424 16:06:27.970482   78877 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.22.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0424 16:06:28.581462   78877 main.go:141] libmachine: Making call to close driver server
I0424 16:06:28.581476   78877 main.go:141] libmachine: (minikube) Calling .Close
I0424 16:06:28.581725   78877 main.go:141] libmachine: (minikube) DBG | Closing plugin on server side
I0424 16:06:28.581764   78877 main.go:141] libmachine: Successfully made call to close driver server
I0424 16:06:28.581771   78877 main.go:141] libmachine: Making call to close connection to plugin binary
I0424 16:06:28.581781   78877 main.go:141] libmachine: Making call to close driver server
I0424 16:06:28.581787   78877 main.go:141] libmachine: (minikube) Calling .Close
I0424 16:06:28.582002   78877 main.go:141] libmachine: Successfully made call to close driver server
I0424 16:06:28.582023   78877 main.go:141] libmachine: Making call to close connection to plugin binary
I0424 16:06:28.582062   78877 main.go:141] libmachine: (minikube) DBG | Closing plugin on server side
I0424 16:06:28.586904   78877 main.go:141] libmachine: Making call to close driver server
I0424 16:06:28.586913   78877 main.go:141] libmachine: (minikube) Calling .Close
I0424 16:06:28.587130   78877 main.go:141] libmachine: Successfully made call to close driver server
I0424 16:06:28.587138   78877 main.go:141] libmachine: Making call to close connection to plugin binary
I0424 16:06:28.587145   78877 main.go:141] libmachine: Making call to close driver server
I0424 16:06:28.587145   78877 main.go:141] libmachine: (minikube) DBG | Closing plugin on server side
I0424 16:06:28.587151   78877 main.go:141] libmachine: (minikube) Calling .Close
I0424 16:06:28.587362   78877 main.go:141] libmachine: Successfully made call to close driver server
I0424 16:06:28.587381   78877 main.go:141] libmachine: Making call to close connection to plugin binary
I0424 16:06:28.587404   78877 main.go:141] libmachine: Making call to close driver server
I0424 16:06:28.587410   78877 main.go:141] libmachine: (minikube) DBG | Closing plugin on server side
I0424 16:06:28.587415   78877 main.go:141] libmachine: (minikube) Calling .Close
I0424 16:06:28.587640   78877 main.go:141] libmachine: (minikube) DBG | Closing plugin on server side
I0424 16:06:28.587692   78877 main.go:141] libmachine: Successfully made call to close driver server
I0424 16:06:28.587710   78877 main.go:141] libmachine: Making call to close connection to plugin binary
I0424 16:06:28.610410   78877 out.go:177] üåü  Enabled addons: storage-provisioner, default-storageclass
I0424 16:06:28.629919   78877 addons.go:492] enable addons completed in 984.173447ms: enabled=[storage-provisioner default-storageclass]
I0424 16:06:28.629955   78877 start.go:233] waiting for cluster config update ...
I0424 16:06:28.629974   78877 start.go:240] writing updated cluster config ...
I0424 16:06:28.631600   78877 ssh_runner.go:195] Run: rm -f paused
I0424 16:06:28.689728   78877 start.go:555] kubectl: 1.25.4, cluster: 1.22.3 (minor skew: 3)
I0424 16:06:28.708929   78877 out.go:177] 
W0424 16:06:28.728124   78877 out.go:239] ‚ùó  /usr/local/bin/kubectl is version 1.25.4, which may have incompatibilities with Kubernetes 1.22.3.
I0424 16:06:28.746034   78877 out.go:177]     ‚ñ™ Want kubectl v1.22.3? Try 'minikube kubectl -- get pods -A'
I0424 16:06:28.784214   78877 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* -- Journal begins at Mon 2023-04-24 08:04:14 UTC, ends at Mon 2023-04-24 09:10:24 UTC. --
Apr 24 08:13:46 minikube dockerd[4591]: time="2023-04-24T08:13:46.161563143Z" level=warning msg="cleanup warnings time=\"2023-04-24T08:13:46Z\" level=info msg=\"starting signal loop\" namespace=moby pid=10832 runtime=io.containerd.runc.v2\n"
Apr 24 08:13:46 minikube dockerd[4585]: time="2023-04-24T08:13:46.246240246Z" level=info msg="ignoring event" container=5651867eeca2d8f5ee140e3d670117f4017dbe675403673db81ee75b9a286451 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Apr 24 08:13:46 minikube dockerd[4591]: time="2023-04-24T08:13:46.247131931Z" level=info msg="shim disconnected" id=5651867eeca2d8f5ee140e3d670117f4017dbe675403673db81ee75b9a286451
Apr 24 08:13:46 minikube dockerd[4591]: time="2023-04-24T08:13:46.248122639Z" level=warning msg="cleaning up after shim disconnected" id=5651867eeca2d8f5ee140e3d670117f4017dbe675403673db81ee75b9a286451 namespace=moby
Apr 24 08:13:46 minikube dockerd[4591]: time="2023-04-24T08:13:46.248178880Z" level=info msg="cleaning up dead shim"
Apr 24 08:13:46 minikube dockerd[4591]: time="2023-04-24T08:13:46.271430087Z" level=warning msg="cleanup warnings time=\"2023-04-24T08:13:46Z\" level=info msg=\"starting signal loop\" namespace=moby pid=10872 runtime=io.containerd.runc.v2\n"
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.428075590Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.432264207Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.432278587Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.432486867Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/62d118fa609e1aa7b254b1d6032c2f89b86892c8bead970615350a0a6182088d pid=24392 runtime=io.containerd.runc.v2
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.475620174Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.476194250Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.476461455Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 24 08:45:21 minikube dockerd[4591]: time="2023-04-24T08:45:21.477271321Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/b6e51cf9983f4d8670e53b2bd5a07653af2d7500fb85b0030b9d0402728b7d9b pid=24416 runtime=io.containerd.runc.v2
Apr 24 08:45:30 minikube dockerd[4591]: time="2023-04-24T08:45:30.260942954Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 24 08:45:30 minikube dockerd[4591]: time="2023-04-24T08:45:30.261104802Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 24 08:45:30 minikube dockerd[4591]: time="2023-04-24T08:45:30.261120693Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 24 08:45:30 minikube dockerd[4591]: time="2023-04-24T08:45:30.263902341Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/f61e4f1d61b3b50c719eb6fe29da2da23f4344594837e2f3cbcb6f1335e6f673 pid=24565 runtime=io.containerd.runc.v2
Apr 24 08:45:32 minikube dockerd[4591]: time="2023-04-24T08:45:32.315086840Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 24 08:45:32 minikube dockerd[4591]: time="2023-04-24T08:45:32.315817615Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 24 08:45:32 minikube dockerd[4591]: time="2023-04-24T08:45:32.316169272Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 24 08:45:32 minikube dockerd[4591]: time="2023-04-24T08:45:32.316817949Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/47dad73f1fe60522496b388d5d5dfcc1f1ce43940d9514ec66a50f78d4e4fba3 pid=24658 runtime=io.containerd.runc.v2
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.642672567Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.643004935Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.643122517Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.643423393Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/5cb06c971a77c4ee50e057b5928ef1c0597e2303aea803d5e7e8c4d116f792c0 pid=32292 runtime=io.containerd.runc.v2
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.775613644Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.775747503Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.775765618Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 24 09:03:13 minikube dockerd[4591]: time="2023-04-24T09:03:13.776418478Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/95efeb6c482ee7d3b8d6cd5e9c0aeea24720d57b054db836f7de9696c0f2f10f pid=32322 runtime=io.containerd.runc.v2
Apr 24 09:03:15 minikube dockerd[4585]: time="2023-04-24T09:03:15.031110234Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:03:45 minikube dockerd[4585]: time="2023-04-24T09:03:45.216304825Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:03:45 minikube dockerd[4585]: time="2023-04-24T09:03:45.218193268Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:03:45 minikube dockerd[4585]: time="2023-04-24T09:03:45.424619693Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:04:15 minikube dockerd[4585]: time="2023-04-24T09:04:15.612177942Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:04:15 minikube dockerd[4585]: time="2023-04-24T09:04:15.615356611Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:04:15 minikube dockerd[4585]: time="2023-04-24T09:04:15.806609077Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:04:45 minikube dockerd[4585]: time="2023-04-24T09:04:45.983882150Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:04:45 minikube dockerd[4585]: time="2023-04-24T09:04:45.986730981Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:04:46 minikube dockerd[4585]: time="2023-04-24T09:04:46.146852196Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:05:16 minikube dockerd[4585]: time="2023-04-24T09:05:16.334364872Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:05:16 minikube dockerd[4585]: time="2023-04-24T09:05:16.336413450Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:05:16 minikube dockerd[4585]: time="2023-04-24T09:05:16.503342906Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:05:46 minikube dockerd[4585]: time="2023-04-24T09:05:46.692173108Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:05:46 minikube dockerd[4585]: time="2023-04-24T09:05:46.694404532Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:05:46 minikube dockerd[4585]: time="2023-04-24T09:05:46.905699629Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:06:17 minikube dockerd[4585]: time="2023-04-24T09:06:17.069625401Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:06:17 minikube dockerd[4585]: time="2023-04-24T09:06:17.072381960Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout"
Apr 24 09:06:37 minikube dockerd[4585]: time="2023-04-24T09:06:37.459373165Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:07:07 minikube dockerd[4585]: time="2023-04-24T09:07:07.641694345Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"
Apr 24 09:07:07 minikube dockerd[4585]: time="2023-04-24T09:07:07.644949009Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"
Apr 24 09:07:08 minikube dockerd[4585]: time="2023-04-24T09:07:08.469413436Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:07:38 minikube dockerd[4585]: time="2023-04-24T09:07:38.662467398Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"
Apr 24 09:07:38 minikube dockerd[4585]: time="2023-04-24T09:07:38.666443165Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"
Apr 24 09:08:37 minikube dockerd[4585]: time="2023-04-24T09:08:37.433977141Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:09:07 minikube dockerd[4585]: time="2023-04-24T09:09:07.624682625Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"
Apr 24 09:09:07 minikube dockerd[4585]: time="2023-04-24T09:09:07.627473416Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"
Apr 24 09:09:09 minikube dockerd[4585]: time="2023-04-24T09:09:09.500262803Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:09:39 minikube dockerd[4585]: time="2023-04-24T09:09:39.799432125Z" level=info msg="Attempting next endpoint for pull after error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"
Apr 24 09:09:39 minikube dockerd[4585]: time="2023-04-24T09:09:39.801500301Z" level=error msg="Handler for POST /v1.41/images/create returned error: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                                  CREATED             STATE               NAME                        ATTEMPT             POD ID
47dad73f1fe60       kicbase/echo-server@sha256:127ac38a2bb9537b7f252addff209ea6801edcac8a92c8b1104dacd66a583ed6            24 minutes ago      Running             bar-app                     0                   b6e51cf9983f4
f61e4f1d61b3b       kicbase/echo-server@sha256:127ac38a2bb9537b7f252addff209ea6801edcac8a92c8b1104dacd66a583ed6            24 minutes ago      Running             foo-app                     0                   62d118fa609e1
fc74ca845ade6       b107f6bf56aee                                                                                          56 minutes ago      Running             hellok8s-container          0                   582f47a986e21
b6b6ba6913fdf       b107f6bf56aee                                                                                          56 minutes ago      Running             hellok8s-container          0                   3bb5117a32b6a
1412bf45142f6       lwenjim/hellok8s@sha256:f4a50b28e838a748268b3a1b0ddd5daee41ce7f7d8c291019e06cfe50e0f499e               56 minutes ago      Running             hellok8s-container          0                   4436de7f38e3d
cf4b9d24209e9       nginx@sha256:63b44e8ddb83d5dd8020327c1f40436e37a6fffd3ef2498a6204df23be6e7e94                          59 minutes ago      Running             nginx-container             0                   ade6bad8b140c
51bff06f066be       nginx@sha256:63b44e8ddb83d5dd8020327c1f40436e37a6fffd3ef2498a6204df23be6e7e94                          59 minutes ago      Running             nginx-container             0                   642028f12320a
1301ab0781d62       kubernetesui/dashboard@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93         About an hour ago   Running             kubernetes-dashboard        0                   564a8b8a6aa12
61efa75a8abd4       kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c   About an hour ago   Running             dashboard-metrics-scraper   0                   071932fc4b084
dee5c83f7a860       6e38f40d628db                                                                                          About an hour ago   Running             storage-provisioner         2                   626c314f13f53
4a1fb249bec5c       0048118155842                                                                                          About an hour ago   Running             etcd                        1                   93ad85551b279
09ce3ab1a3c91       8d147537fb7d1                                                                                          About an hour ago   Running             coredns                     1                   d12c143ee8783
059cd3ca0ea53       0aa9c7e31d307                                                                                          About an hour ago   Running             kube-scheduler              2                   7de889337d156
d1acb3c31943f       05c905cef780c                                                                                          About an hour ago   Running             kube-controller-manager     1                   451e4bf56b064
529b541d3e694       53224b502ea4d                                                                                          About an hour ago   Running             kube-apiserver              2                   5e5be61b189fe
956e0ed79a82d       6120bd723dced                                                                                          About an hour ago   Running             kube-proxy                  1                   cb4ffe4448b8b
a6f8814659a88       0aa9c7e31d307                                                                                          About an hour ago   Exited              kube-scheduler              1                   4ee4d69340de8
a5b31f0fa2857       6e38f40d628db                                                                                          About an hour ago   Exited              storage-provisioner         1                   2fe020430d663
46f923d79cfca       8d147537fb7d1                                                                                          About an hour ago   Exited              coredns                     0                   5ea25ac76e212
7ca86fde73ba5       0048118155842                                                                                          About an hour ago   Exited              etcd                        0                   60729e0666f8a

* 
* ==> coredns [09ce3ab1a3c9] <==
* [WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration MD5 = 07d7c5ad4525bf2c472eaef020d0184d
CoreDNS-1.8.4
linux/amd64, go1.16.4, 053c4d5
[INFO] 127.0.0.1:42949 - 33655 "HINFO IN 8611048363721928591.3009175100915648622. udp 57 false 512" NXDOMAIN qr,rd,ra 132 1.029139881s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"

* 
* ==> coredns [46f923d79cfc] <==
* .:53
[INFO] plugin/reload: Running configuration MD5 = 07d7c5ad4525bf2c472eaef020d0184d
CoreDNS-1.8.4
linux/amd64, go1.16.4, 053c4d5
[INFO] 127.0.0.1:50127 - 12933 "HINFO IN 6853571102869643926.1829290810280551312. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.01094671s
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane,master
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=ddac20b4b34a9c8c857fc602203b6ba2679794d3
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_04_24T16_05_14_0700
                    minikube.k8s.io/version=v1.29.0
                    node-role.kubernetes.io/control-plane=
                    node-role.kubernetes.io/master=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Mon, 24 Apr 2023 08:05:07 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Mon, 24 Apr 2023 09:10:19 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Mon, 24 Apr 2023 09:06:00 +0000   Mon, 24 Apr 2023 08:05:02 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Mon, 24 Apr 2023 09:06:00 +0000   Mon, 24 Apr 2023 08:05:02 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Mon, 24 Apr 2023 09:06:00 +0000   Mon, 24 Apr 2023 08:05:02 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Mon, 24 Apr 2023 09:06:00 +0000   Mon, 24 Apr 2023 08:05:23 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.64.2
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  17784752Ki
  hugepages-2Mi:      0
  memory:             3914660Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  17784752Ki
  hugepages-2Mi:      0
  memory:             3914660Ki
  pods:               110
System Info:
  Machine ID:                 6deae6b60ba24bd299c87f3c59175d04
  System UUID:                8e9611ed-0000-0000-a9a9-acde48001122
  Boot ID:                    b353bfa9-d9b2-47d4-9dc6-f74026244c95
  Kernel Version:             5.10.57
  OS Image:                   Buildroot 2021.02.12
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://20.10.23
  Kubelet Version:            v1.22.3
  Kube-Proxy Version:         v1.22.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (19 in total)
  Namespace                   Name                                          CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                          ------------  ----------  ---------------  -------------  ---
  default                     bar-app                                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         25m
  default                     foo-app                                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         25m
  default                     hellok8s-deployment-7cf4657f4d-7cdtp          0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         56m
  default                     hellok8s-deployment-7cf4657f4d-8927m          0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         56m
  default                     hellok8s-deployment-7cf4657f4d-l5f8z          0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         56m
  default                     nginx-deployment-d47fd7f66-hsh2g              0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         60m
  default                     nginx-deployment-d47fd7f66-sqdz6              0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         60m
  ingress-nginx               ingress-nginx-admission-create--1-ghwff       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7m12s
  ingress-nginx               ingress-nginx-admission-patch--1-7dr44        0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7m12s
  ingress-nginx               ingress-nginx-controller-7695595dd9-ndkdm     100m (5%!)(MISSING)     0 (0%!)(MISSING)      90Mi (2%!)(MISSING)        0 (0%!)(MISSING)         7m12s
  kube-system                 coredns-78fcd69978-6j56x                      100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     65m
  kube-system                 etcd-minikube                                 100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         65m
  kube-system                 kube-apiserver-minikube                       250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         65m
  kube-system                 kube-controller-manager-minikube              200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         65m
  kube-system                 kube-proxy-rd9vt                              0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         65m
  kube-system                 kube-scheduler-minikube                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         65m
  kube-system                 storage-provisioner                           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         65m
  kubernetes-dashboard        dashboard-metrics-scraper-687748788c-5nrbp    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         62m
  kubernetes-dashboard        kubernetes-dashboard-744fc84fb7-wxtcx         0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         62m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%!)(MISSING)  0 (0%!)(MISSING)
  memory             260Mi (6%!)(MISSING)  170Mi (4%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:              <none>

* 
* ==> dmesg <==
* [Apr24 08:03] ERROR: earlyprintk= earlyser already used
[  +0.000000] You have booted with nomodeset. This means your GPU drivers are DISABLED
[  +0.000001] Any video related functionality will be severely degraded, and you may not even be able to suspend the system properly
[  +0.000000] Unless you actually understand what nomodeset does, you should reboot without enabling it
[  +0.239988] ACPI BIOS Warning (bug): Incorrect checksum in table [DSDT] - 0xBE, should be 0x1B (20200925/tbprint-173)
[Apr24 08:04] ACPI Error: Could not enable RealTimeClock event (20200925/evxfevnt-182)
[  +0.000004] ACPI Warning: Could not enable fixed event - RealTimeClock (4) (20200925/evxface-618)
[  +0.018642] platform regulatory.0: Direct firmware load for regulatory.db failed with error -2
[  +4.120238] systemd-fstab-generator[123]: Ignoring "noauto" for root device
[  +0.105527] systemd[1]: systemd-journald.service: unit configures an IP firewall, but the local system does not support BPF/cgroup firewalling.
[  +0.000002] systemd[1]: (This warning is only shown for the first unit using IP firewalling.)
[  +3.012970] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory
[  +0.000039] NFSD: unable to find recovery directory /var/lib/nfs/v4recovery
[  +0.000001] NFSD: Unable to initialize client recovery tracking! (-2)
[  +3.480973] systemd-fstab-generator[543]: Ignoring "noauto" for root device
[  +0.231941] systemd-fstab-generator[561]: Ignoring "noauto" for root device
[ +18.334287] systemd-fstab-generator[910]: Ignoring "noauto" for root device
[  +2.369818] kauditd_printk_skb: 16 callbacks suppressed
[  +0.578571] systemd-fstab-generator[1072]: Ignoring "noauto" for root device
[  +0.756691] systemd-fstab-generator[1107]: Ignoring "noauto" for root device
[  +0.218858] systemd-fstab-generator[1118]: Ignoring "noauto" for root device
[  +0.243018] systemd-fstab-generator[1131]: Ignoring "noauto" for root device
[ +11.255246] systemd-fstab-generator[1534]: Ignoring "noauto" for root device
[  +1.363729] kauditd_printk_skb: 68 callbacks suppressed
[Apr24 08:05] hrtimer: interrupt took 950981 ns
[  +0.486972] systemd-fstab-generator[2695]: Ignoring "noauto" for root device
[ +12.811061] kauditd_printk_skb: 6 callbacks suppressed
[  +8.642613] kauditd_printk_skb: 13 callbacks suppressed
[ +16.328365] systemd-fstab-generator[3771]: Ignoring "noauto" for root device
[  +0.509844] systemd-fstab-generator[3802]: Ignoring "noauto" for root device
[  +0.294453] systemd-fstab-generator[3813]: Ignoring "noauto" for root device
[  +0.331792] systemd-fstab-generator[3833]: Ignoring "noauto" for root device
[Apr24 08:06] kauditd_printk_skb: 30 callbacks suppressed
[Apr24 08:10] kauditd_printk_skb: 3 callbacks suppressed
[Apr24 08:13] kauditd_printk_skb: 6 callbacks suppressed

* 
* ==> etcd [4a1fb249bec5] <==
* {"level":"info","ts":"2023-04-24T08:06:18.648Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.64.2:2379"]}
{"level":"info","ts":"2023-04-24T08:06:18.649Z","caller":"embed/etcd.go:307","msg":"starting an etcd server","etcd-version":"3.5.0","git-sha":"946a5a6f2","go-version":"go1.16.3","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":true,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.64.2:2380"],"listen-peer-urls":["https://192.168.64.2:2380"],"advertise-client-urls":["https://192.168.64.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.64.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":false,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2023-04-24T08:06:18.651Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"1.248602ms"}
{"level":"info","ts":"2023-04-24T08:06:18.661Z","caller":"etcdserver/server.go:526","msg":"No snapshot found. Recovering WAL from scratch!"}
{"level":"info","ts":"2023-04-24T08:06:18.673Z","caller":"etcdserver/raft.go:483","msg":"restarting local member","cluster-id":"bde34cecb57cc33f","local-member-id":"77ee71d7bb7b0f2","commit-index":508}
{"level":"info","ts":"2023-04-24T08:06:18.677Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 switched to configuration voters=()"}
{"level":"info","ts":"2023-04-24T08:06:18.677Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became follower at term 2"}
{"level":"info","ts":"2023-04-24T08:06:18.677Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft 77ee71d7bb7b0f2 [peers: [], term: 2, commit: 508, applied: 0, lastindex: 508, lastterm: 2]"}
{"level":"info","ts":"2023-04-24T08:06:18.677Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-04-24T08:06:18.677Z","caller":"membership/cluster.go:276","msg":"recovered/added member from store","cluster-id":"bde34cecb57cc33f","local-member-id":"77ee71d7bb7b0f2","recovered-remote-peer-id":"77ee71d7bb7b0f2","recovered-remote-peer-urls":["https://192.168.64.2:2380"]}
{"level":"info","ts":"2023-04-24T08:06:18.678Z","caller":"membership/cluster.go:285","msg":"set cluster version from store","cluster-version":"3.5"}
{"level":"warn","ts":"2023-04-24T08:06:18.682Z","caller":"auth/store.go:1220","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-04-24T08:06:18.687Z","caller":"mvcc/kvstore.go:415","msg":"kvstore restored","current-rev":494}
{"level":"info","ts":"2023-04-24T08:06:18.688Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-04-24T08:06:18.693Z","caller":"etcdserver/server.go:834","msg":"starting etcd server","local-member-id":"77ee71d7bb7b0f2","local-server-version":"3.5.0","cluster-id":"bde34cecb57cc33f","cluster-version":"3.5"}
{"level":"info","ts":"2023-04-24T08:06:18.699Z","caller":"etcdserver/server.go:728","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"77ee71d7bb7b0f2","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2023-04-24T08:06:18.701Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 switched to configuration voters=(540123119146742002)"}
{"level":"info","ts":"2023-04-24T08:06:18.702Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-04-24T08:06:18.702Z","caller":"embed/etcd.go:276","msg":"now serving peer/client/metrics","local-member-id":"77ee71d7bb7b0f2","initial-advertise-peer-urls":["https://192.168.64.2:2380"],"listen-peer-urls":["https://192.168.64.2:2380"],"advertise-client-urls":["https://192.168.64.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.64.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-04-24T08:06:18.702Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-04-24T08:06:18.701Z","caller":"membership/cluster.go:393","msg":"added member","cluster-id":"bde34cecb57cc33f","local-member-id":"77ee71d7bb7b0f2","added-peer-id":"77ee71d7bb7b0f2","added-peer-peer-urls":["https://192.168.64.2:2380"]}
{"level":"info","ts":"2023-04-24T08:06:18.705Z","caller":"membership/cluster.go:523","msg":"updated cluster version","cluster-id":"bde34cecb57cc33f","local-member-id":"77ee71d7bb7b0f2","from":"3.5","to":"3.5"}
{"level":"info","ts":"2023-04-24T08:06:18.709Z","caller":"embed/etcd.go:580","msg":"serving peer traffic","address":"192.168.64.2:2380"}
{"level":"info","ts":"2023-04-24T08:06:18.709Z","caller":"embed/etcd.go:552","msg":"cmux::serve","address":"192.168.64.2:2380"}
{"level":"info","ts":"2023-04-24T08:06:19.280Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 is starting a new election at term 2"}
{"level":"info","ts":"2023-04-24T08:06:19.280Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became pre-candidate at term 2"}
{"level":"info","ts":"2023-04-24T08:06:19.280Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 received MsgPreVoteResp from 77ee71d7bb7b0f2 at term 2"}
{"level":"info","ts":"2023-04-24T08:06:19.280Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became candidate at term 3"}
{"level":"info","ts":"2023-04-24T08:06:19.280Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 received MsgVoteResp from 77ee71d7bb7b0f2 at term 3"}
{"level":"info","ts":"2023-04-24T08:06:19.280Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became leader at term 3"}
{"level":"info","ts":"2023-04-24T08:06:19.280Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: 77ee71d7bb7b0f2 elected leader 77ee71d7bb7b0f2 at term 3"}
{"level":"info","ts":"2023-04-24T08:06:19.281Z","caller":"etcdserver/server.go:2027","msg":"published local member to cluster through raft","local-member-id":"77ee71d7bb7b0f2","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.64.2:2379]}","request-path":"/0/members/77ee71d7bb7b0f2/attributes","cluster-id":"bde34cecb57cc33f","publish-timeout":"7s"}
{"level":"info","ts":"2023-04-24T08:06:19.281Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-04-24T08:06:19.286Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-04-24T08:06:19.296Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-04-24T08:06:19.312Z","caller":"etcdmain/main.go:47","msg":"notifying init daemon"}
{"level":"info","ts":"2023-04-24T08:06:19.312Z","caller":"etcdmain/main.go:53","msg":"successfully notified init daemon"}
{"level":"info","ts":"2023-04-24T08:06:19.320Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"192.168.64.2:2379"}
{"level":"info","ts":"2023-04-24T08:16:20.085Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":971}
{"level":"info","ts":"2023-04-24T08:16:20.087Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":971,"took":"1.308535ms"}
{"level":"info","ts":"2023-04-24T08:21:20.093Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1289}
{"level":"info","ts":"2023-04-24T08:21:20.095Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":1289,"took":"852.1¬µs"}
{"level":"info","ts":"2023-04-24T08:26:20.098Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1498}
{"level":"info","ts":"2023-04-24T08:26:20.100Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":1498,"took":"780.468¬µs"}
{"level":"info","ts":"2023-04-24T08:31:20.103Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1707}
{"level":"info","ts":"2023-04-24T08:31:20.104Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":1707,"took":"570.173¬µs"}
{"level":"info","ts":"2023-04-24T08:36:20.110Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":1916}
{"level":"info","ts":"2023-04-24T08:36:20.111Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":1916,"took":"789.007¬µs"}
{"level":"info","ts":"2023-04-24T08:41:20.115Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2126}
{"level":"info","ts":"2023-04-24T08:41:20.117Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":2126,"took":"1.630542ms"}
{"level":"info","ts":"2023-04-24T08:46:20.122Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2334}
{"level":"info","ts":"2023-04-24T08:46:20.123Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":2334,"took":"682.77¬µs"}
{"level":"info","ts":"2023-04-24T08:51:20.128Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2576}
{"level":"info","ts":"2023-04-24T08:51:20.129Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":2576,"took":"673.774¬µs"}
{"level":"info","ts":"2023-04-24T08:56:20.135Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2786}
{"level":"info","ts":"2023-04-24T08:56:20.136Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":2786,"took":"987.903¬µs"}
{"level":"info","ts":"2023-04-24T09:01:20.140Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":2996}
{"level":"info","ts":"2023-04-24T09:01:20.141Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":2996,"took":"748.167¬µs"}
{"level":"info","ts":"2023-04-24T09:06:20.145Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":3208}
{"level":"info","ts":"2023-04-24T09:06:20.146Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":3208,"took":"833.136¬µs"}

* 
* ==> etcd [7ca86fde73ba] <==
* {"level":"info","ts":"2023-04-24T08:05:01.209Z","caller":"etcdmain/etcd.go:72","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.64.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--initial-advertise-peer-urls=https://192.168.64.2:2380","--initial-cluster=minikube=https://192.168.64.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.64.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.64.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2023-04-24T08:05:01.210Z","caller":"embed/etcd.go:131","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.64.2:2380"]}
{"level":"info","ts":"2023-04-24T08:05:01.210Z","caller":"embed/etcd.go:478","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-04-24T08:05:01.211Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.64.2:2379"]}
{"level":"info","ts":"2023-04-24T08:05:01.214Z","caller":"embed/etcd.go:307","msg":"starting an etcd server","etcd-version":"3.5.0","git-sha":"946a5a6f2","go-version":"go1.16.3","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.64.2:2380"],"listen-peer-urls":["https://192.168.64.2:2380"],"advertise-client-urls":["https://192.168.64.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.64.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://192.168.64.2:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":false,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2023-04-24T08:05:01.217Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"1.869337ms"}
{"level":"info","ts":"2023-04-24T08:05:01.225Z","caller":"etcdserver/raft.go:448","msg":"starting local member","local-member-id":"77ee71d7bb7b0f2","cluster-id":"bde34cecb57cc33f"}
{"level":"info","ts":"2023-04-24T08:05:01.226Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 switched to configuration voters=()"}
{"level":"info","ts":"2023-04-24T08:05:01.226Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became follower at term 0"}
{"level":"info","ts":"2023-04-24T08:05:01.226Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft 77ee71d7bb7b0f2 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2023-04-24T08:05:01.226Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became follower at term 1"}
{"level":"info","ts":"2023-04-24T08:05:01.226Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 switched to configuration voters=(540123119146742002)"}
{"level":"warn","ts":"2023-04-24T08:05:01.241Z","caller":"auth/store.go:1220","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-04-24T08:05:01.249Z","caller":"mvcc/kvstore.go:415","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2023-04-24T08:05:01.261Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-04-24T08:05:01.275Z","caller":"etcdserver/server.go:843","msg":"starting etcd server","local-member-id":"77ee71d7bb7b0f2","local-server-version":"3.5.0","cluster-version":"to_be_decided"}
{"level":"info","ts":"2023-04-24T08:05:01.278Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 switched to configuration voters=(540123119146742002)"}
{"level":"info","ts":"2023-04-24T08:05:01.280Z","caller":"membership/cluster.go:393","msg":"added member","cluster-id":"bde34cecb57cc33f","local-member-id":"77ee71d7bb7b0f2","added-peer-id":"77ee71d7bb7b0f2","added-peer-peer-urls":["https://192.168.64.2:2380"]}
{"level":"info","ts":"2023-04-24T08:05:01.280Z","caller":"etcdserver/server.go:728","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"77ee71d7bb7b0f2","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2023-04-24T08:05:01.305Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-04-24T08:05:01.306Z","caller":"embed/etcd.go:276","msg":"now serving peer/client/metrics","local-member-id":"77ee71d7bb7b0f2","initial-advertise-peer-urls":["https://192.168.64.2:2380"],"listen-peer-urls":["https://192.168.64.2:2380"],"advertise-client-urls":["https://192.168.64.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.64.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-04-24T08:05:01.306Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-04-24T08:05:01.309Z","caller":"embed/etcd.go:580","msg":"serving peer traffic","address":"192.168.64.2:2380"}
{"level":"info","ts":"2023-04-24T08:05:01.309Z","caller":"embed/etcd.go:552","msg":"cmux::serve","address":"192.168.64.2:2380"}
{"level":"info","ts":"2023-04-24T08:05:01.429Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 is starting a new election at term 1"}
{"level":"info","ts":"2023-04-24T08:05:01.429Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became pre-candidate at term 1"}
{"level":"info","ts":"2023-04-24T08:05:01.429Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 received MsgPreVoteResp from 77ee71d7bb7b0f2 at term 1"}
{"level":"info","ts":"2023-04-24T08:05:01.429Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became candidate at term 2"}
{"level":"info","ts":"2023-04-24T08:05:01.429Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 received MsgVoteResp from 77ee71d7bb7b0f2 at term 2"}
{"level":"info","ts":"2023-04-24T08:05:01.429Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"77ee71d7bb7b0f2 became leader at term 2"}
{"level":"info","ts":"2023-04-24T08:05:01.429Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: 77ee71d7bb7b0f2 elected leader 77ee71d7bb7b0f2 at term 2"}
{"level":"info","ts":"2023-04-24T08:05:01.430Z","caller":"etcdserver/server.go:2476","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2023-04-24T08:05:01.431Z","caller":"membership/cluster.go:531","msg":"set initial cluster version","cluster-id":"bde34cecb57cc33f","local-member-id":"77ee71d7bb7b0f2","cluster-version":"3.5"}
{"level":"info","ts":"2023-04-24T08:05:01.434Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-04-24T08:05:01.434Z","caller":"etcdserver/server.go:2500","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2023-04-24T08:05:01.434Z","caller":"etcdserver/server.go:2027","msg":"published local member to cluster through raft","local-member-id":"77ee71d7bb7b0f2","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.64.2:2379]}","request-path":"/0/members/77ee71d7bb7b0f2/attributes","cluster-id":"bde34cecb57cc33f","publish-timeout":"7s"}
{"level":"info","ts":"2023-04-24T08:05:01.435Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-04-24T08:05:01.439Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"192.168.64.2:2379"}
{"level":"info","ts":"2023-04-24T08:05:01.439Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-04-24T08:05:01.447Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-04-24T08:05:01.448Z","caller":"etcdmain/main.go:47","msg":"notifying init daemon"}
{"level":"info","ts":"2023-04-24T08:05:01.449Z","caller":"etcdmain/main.go:53","msg":"successfully notified init daemon"}
{"level":"info","ts":"2023-04-24T08:05:51.913Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2023-04-24T08:05:51.913Z","caller":"embed/etcd.go:367","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.64.2:2380"],"advertise-client-urls":["https://192.168.64.2:2379"]}
WARNING: 2023/04/24 08:05:51 [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1:2379 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
WARNING: 2023/04/24 08:05:51 [core] grpc: addrConn.createTransport failed to connect to {192.168.64.2:2379 192.168.64.2:2379 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 192.168.64.2:2379: connect: connection refused". Reconnecting...
{"level":"info","ts":"2023-04-24T08:05:51.998Z","caller":"etcdserver/server.go:1438","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"77ee71d7bb7b0f2","current-leader-member-id":"77ee71d7bb7b0f2"}
{"level":"info","ts":"2023-04-24T08:05:52.000Z","caller":"embed/etcd.go:562","msg":"stopping serving peer traffic","address":"192.168.64.2:2380"}
{"level":"info","ts":"2023-04-24T08:05:52.002Z","caller":"embed/etcd.go:567","msg":"stopped serving peer traffic","address":"192.168.64.2:2380"}
{"level":"info","ts":"2023-04-24T08:05:52.002Z","caller":"embed/etcd.go:369","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.64.2:2380"],"advertise-client-urls":["https://192.168.64.2:2379"]}

* 
* ==> kernel <==
*  09:10:26 up  1:06,  0 users,  load average: 0.62, 0.50, 0.39
Linux minikube 5.10.57 #1 SMP Fri Jan 27 18:05:35 UTC 2023 x86_64 GNU/Linux
PRETTY_NAME="Buildroot 2021.02.12"

* 
* ==> kube-apiserver [529b541d3e69] <==
* W0424 08:06:22.681574       1 genericapiserver.go:455] Skipping API flowcontrol.apiserver.k8s.io/v1alpha1 because it has no resources.
W0424 08:06:22.696379       1 genericapiserver.go:455] Skipping API apps/v1beta2 because it has no resources.
W0424 08:06:22.696405       1 genericapiserver.go:455] Skipping API apps/v1beta1 because it has no resources.
W0424 08:06:22.701461       1 genericapiserver.go:455] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
I0424 08:06:22.712901       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I0424 08:06:22.712951       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
W0424 08:06:22.788188       1 genericapiserver.go:455] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I0424 08:06:26.489651       1 dynamic_cafile_content.go:155] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0424 08:06:26.490167       1 dynamic_cafile_content.go:155] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0424 08:06:26.490569       1 dynamic_serving_content.go:129] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I0424 08:06:26.490958       1 secure_serving.go:266] Serving securely on [::]:8443
I0424 08:06:26.491193       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0424 08:06:26.491955       1 customresource_discovery_controller.go:209] Starting DiscoveryController
I0424 08:06:26.514453       1 available_controller.go:491] Starting AvailableConditionController
I0424 08:06:26.514474       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0424 08:06:26.514501       1 controller.go:83] Starting OpenAPI AggregationController
I0424 08:06:26.514577       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0424 08:06:26.514586       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0424 08:06:26.514608       1 autoregister_controller.go:141] Starting autoregister controller
I0424 08:06:26.514613       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0424 08:06:26.515532       1 dynamic_serving_content.go:129] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0424 08:06:26.528344       1 apf_controller.go:312] Starting API Priority and Fairness config controller
I0424 08:06:26.528404       1 controller.go:85] Starting OpenAPI controller
I0424 08:06:26.528421       1 naming_controller.go:291] Starting NamingConditionController
I0424 08:06:26.528432       1 establishing_controller.go:76] Starting EstablishingController
I0424 08:06:26.528489       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0424 08:06:26.528506       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0424 08:06:26.528517       1 crd_finalizer.go:266] Starting CRDFinalizer
I0424 08:06:26.556516       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0424 08:06:26.556534       1 shared_informer.go:240] Waiting for caches to sync for crd-autoregister
I0424 08:06:26.557218       1 dynamic_cafile_content.go:155] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0424 08:06:26.557296       1 dynamic_cafile_content.go:155] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0424 08:06:26.557323       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0424 08:06:26.557329       1 shared_informer.go:240] Waiting for caches to sync for cluster_authentication_trust_controller
E0424 08:06:26.641647       1 controller.go:152] Unable to remove old endpoints from kubernetes service: StorageError: key not found, Code: 1, Key: /registry/masterleases/192.168.64.2, ResourceVersion: 0, AdditionalErrorMsg: 
I0424 08:06:26.914606       1 controller.go:611] quota admission added evaluator for: leases.coordination.k8s.io
I0424 08:06:26.915170       1 cache.go:39] Caches are synced for autoregister controller
I0424 08:06:26.915578       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0424 08:06:26.915610       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0424 08:06:26.928514       1 apf_controller.go:317] Running API Priority and Fairness config worker
I0424 08:06:26.939940       1 shared_informer.go:247] Caches are synced for node_authorizer 
I0424 08:06:26.957290       1 shared_informer.go:247] Caches are synced for crd-autoregister 
I0424 08:06:26.957355       1 shared_informer.go:247] Caches are synced for cluster_authentication_trust_controller 
I0424 08:06:27.147176       1 controller.go:611] quota admission added evaluator for: events.events.k8s.io
I0424 08:06:27.489804       1 controller.go:132] OpenAPI AggregationController: action for item : Nothing (removed from the queue).
I0424 08:06:27.490080       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0424 08:06:27.536484       1 storage_scheduling.go:148] all system priority classes are created successfully or already exist.
I0424 08:06:28.751606       1 controller.go:611] quota admission added evaluator for: endpoints
I0424 08:06:39.177233       1 controller.go:611] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0424 08:07:29.519436       1 controller.go:611] quota admission added evaluator for: namespaces
I0424 08:07:29.560566       1 controller.go:611] quota admission added evaluator for: serviceaccounts
I0424 08:07:29.601948       1 controller.go:611] quota admission added evaluator for: deployments.apps
I0424 08:07:29.627292       1 controller.go:611] quota admission added evaluator for: replicasets.apps
I0424 08:07:29.652301       1 controller.go:611] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0424 08:07:29.705758       1 controller.go:611] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0424 08:10:24.142344       1 controller.go:611] quota admission added evaluator for: ingresses.networking.k8s.io
W0424 08:29:45.253221       1 watcher.go:229] watch chan error: etcdserver: mvcc: required revision has been compacted
W0424 08:43:57.361151       1 watcher.go:229] watch chan error: etcdserver: mvcc: required revision has been compacted
W0424 08:52:46.598307       1 watcher.go:229] watch chan error: etcdserver: mvcc: required revision has been compacted
I0424 09:03:12.863051       1 controller.go:611] quota admission added evaluator for: jobs.batch

* 
* ==> kube-controller-manager [d1acb3c31943] <==
* E0424 08:07:29.741666       1 replica_set.go:536] sync "kubernetes-dashboard/dashboard-metrics-scraper-687748788c" failed with pods "dashboard-metrics-scraper-687748788c-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0424 08:07:29.742802       1 event.go:291] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-687748788c" kind="ReplicaSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="Error creating: pods \"dashboard-metrics-scraper-687748788c-\" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount \"kubernetes-dashboard\" not found"
E0424 08:07:29.755074       1 replica_set.go:536] sync "kubernetes-dashboard/kubernetes-dashboard-744fc84fb7" failed with pods "kubernetes-dashboard-744fc84fb7-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0424 08:07:29.793744       1 event.go:291] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-687748788c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: dashboard-metrics-scraper-687748788c-5nrbp"
I0424 08:07:29.808600       1 event.go:291] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-744fc84fb7" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kubernetes-dashboard-744fc84fb7-wxtcx"
I0424 08:10:15.616148       1 event.go:291] "Event occurred" object="default/hellok8s-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set hellok8s-deployment-5d5545b69c to 3"
I0424 08:10:15.638104       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-5d5545b69c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: hellok8s-deployment-5d5545b69c-bmgs9"
I0424 08:10:15.681661       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-5d5545b69c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: hellok8s-deployment-5d5545b69c-vrkf5"
I0424 08:10:15.684344       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-5d5545b69c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: hellok8s-deployment-5d5545b69c-jklzp"
I0424 08:10:19.315801       1 event.go:291] "Event occurred" object="default/nginx-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set nginx-deployment-d47fd7f66 to 2"
I0424 08:10:19.340846       1 event.go:291] "Event occurred" object="default/nginx-deployment-d47fd7f66" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: nginx-deployment-d47fd7f66-hsh2g"
I0424 08:10:19.394490       1 event.go:291] "Event occurred" object="default/nginx-deployment-d47fd7f66" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: nginx-deployment-d47fd7f66-sqdz6"
I0424 08:13:32.183653       1 event.go:291] "Event occurred" object="default/hellok8s-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set hellok8s-deployment-7cf4657f4d to 1"
I0424 08:13:32.202201       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-7cf4657f4d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: hellok8s-deployment-7cf4657f4d-7cdtp"
I0424 08:13:40.781345       1 event.go:291] "Event occurred" object="default/hellok8s-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set hellok8s-deployment-5d5545b69c to 2"
I0424 08:13:40.799568       1 event.go:291] "Event occurred" object="default/hellok8s-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set hellok8s-deployment-7cf4657f4d to 2"
I0424 08:13:40.804825       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-5d5545b69c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: hellok8s-deployment-5d5545b69c-bmgs9"
I0424 08:13:40.846979       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-7cf4657f4d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: hellok8s-deployment-7cf4657f4d-l5f8z"
I0424 08:13:43.472580       1 event.go:291] "Event occurred" object="default/hellok8s-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set hellok8s-deployment-5d5545b69c to 1"
I0424 08:13:43.515767       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-5d5545b69c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: hellok8s-deployment-5d5545b69c-vrkf5"
I0424 08:13:43.535692       1 event.go:291] "Event occurred" object="default/hellok8s-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set hellok8s-deployment-7cf4657f4d to 3"
I0424 08:13:43.547165       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-7cf4657f4d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: hellok8s-deployment-7cf4657f4d-8927m"
I0424 08:13:45.990647       1 event.go:291] "Event occurred" object="default/hellok8s-deployment" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set hellok8s-deployment-5d5545b69c to 0"
I0424 08:13:46.034606       1 event.go:291] "Event occurred" object="default/hellok8s-deployment-5d5545b69c" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: hellok8s-deployment-5d5545b69c-jklzp"
W0424 08:13:47.027553       1 endpointslice_controller.go:306] Error syncing endpoint slices for service "default/service-hellok8s-clusterip", retrying. Error: EndpointSlice informer cache is out of date
I0424 09:03:12.874488       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set ingress-nginx-controller-7695595dd9 to 1"
I0424 09:03:12.889916       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:03:12.989670       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:03:13.038100       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller-7695595dd9" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-controller-7695595dd9-ndkdm"
I0424 09:03:13.044363       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-admission-create" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-create--1-ghwff"
I0424 09:03:13.046503       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:03:13.070483       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:03:13.095609       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:03:13.112215       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-admission-patch" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-patch--1-7dr44"
I0424 09:03:13.121434       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:03:13.131230       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:03:13.167287       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:03:13.269457       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:03:13.312316       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:03:45.712246       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:04:00.305383       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:04:16.357650       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:04:28.308494       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:04:57.318131       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:05:10.307201       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:05:27.313060       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:05:38.301830       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:05:58.303257       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:06:11.324784       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:06:29.323305       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:06:38.902723       1 cleaner.go:172] Cleaning CSR "csr-jf5gk" as it is more than 1h0m0s old and approved.
I0424 09:06:41.298595       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:07:18.314309       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:07:30.316743       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:07:54.302875       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:08:08.295139       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:09:23.307362       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:09:36.330560       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0424 09:09:53.313775       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0424 09:10:04.306139       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch

* 
* ==> kube-proxy [956e0ed79a82] <==
* I0424 08:06:26.911732       1 node.go:172] Successfully retrieved node IP: 192.168.64.2
I0424 08:06:26.917283       1 server_others.go:140] Detected node IP 192.168.64.2
W0424 08:06:26.917413       1 server_others.go:565] Unknown proxy mode "", assuming iptables proxy
W0424 08:06:27.131104       1 server_others.go:197] No iptables support for IPv6: exit status 3
I0424 08:06:27.131257       1 server_others.go:208] kube-proxy running in single-stack IPv4 mode
I0424 08:06:27.131274       1 server_others.go:212] Using iptables Proxier.
I0424 08:06:27.132151       1 server.go:649] Version: v1.22.3
I0424 08:06:27.138200       1 config.go:315] Starting service config controller
I0424 08:06:27.138246       1 shared_informer.go:240] Waiting for caches to sync for service config
I0424 08:06:27.138315       1 config.go:224] Starting endpoint slice config controller
I0424 08:06:27.138323       1 shared_informer.go:240] Waiting for caches to sync for endpoint slice config
I0424 08:06:27.239068       1 shared_informer.go:247] Caches are synced for endpoint slice config 
I0424 08:06:27.239745       1 shared_informer.go:247] Caches are synced for service config 

* 
* ==> kube-scheduler [059cd3ca0ea5] <==
* I0424 08:06:19.779311       1 serving.go:347] Generated self-signed cert in-memory
W0424 08:06:26.636906       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0424 08:06:26.637040       1 authentication.go:345] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0424 08:06:26.637054       1 authentication.go:346] Continuing without authentication configuration. This may treat all requests as anonymous.
W0424 08:06:26.637061       1 authentication.go:347] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0424 08:06:26.759374       1 secure_serving.go:200] Serving securely on 127.0.0.1:10259
I0424 08:06:26.759878       1 configmap_cafile_content.go:201] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0424 08:06:26.760287       1 shared_informer.go:240] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0424 08:06:26.760557       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
E0424 08:06:26.782333       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0424 08:06:26.783823       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0424 08:06:26.786086       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0424 08:06:26.786778       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0424 08:06:26.787347       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0424 08:06:26.787728       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0424 08:06:26.788203       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0424 08:06:26.788462       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0424 08:06:26.788875       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0424 08:06:26.789378       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0424 08:06:26.789674       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0424 08:06:26.790054       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0424 08:06:26.792200       1 reflector.go:138] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:205: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0424 08:06:26.798293       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1beta1.CSIStorageCapacity: failed to list *v1beta1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0424 08:06:26.798726       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0424 08:06:28.050411       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
E0424 08:06:28.050501       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
E0424 08:06:28.050533       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
E0424 08:06:28.050670       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
E0424 08:06:28.050685       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
E0424 08:06:28.051341       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
E0424 08:06:28.051626       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
I0424 08:06:28.161159       1 shared_informer.go:247] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file 

* 
* ==> kube-scheduler [a6f8814659a8] <==
* I0424 08:05:57.629545       1 serving.go:347] Generated self-signed cert in-memory
W0424 08:06:08.096555       1 authentication.go:345] Error looking up in-cluster authentication configuration: Get "https://192.168.64.2:8443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": net/http: TLS handshake timeout
W0424 08:06:08.096588       1 authentication.go:346] Continuing without authentication configuration. This may treat all requests as anonymous.
W0424 08:06:08.096596       1 authentication.go:347] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false

* 
* ==> kubelet <==
* -- Journal begins at Mon 2023-04-24 08:04:14 UTC, ends at Mon 2023-04-24 09:10:26 UTC. --
Apr 24 09:05:27 minikube kubelet[2720]: E0424 09:05:27.292610    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:05:46 minikube kubelet[2720]: E0424 09:05:46.695103    2720 remote_image.go:114] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:05:46 minikube kubelet[2720]: E0424 09:05:46.695174    2720 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:05:46 minikube kubelet[2720]: E0424 09:05:46.695384    2720 kuberuntime_manager.go:898] container &Container{Name:create,Image:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f,Command:[],Args:[create --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc --namespace=$(POD_NAMESPACE) --secret-name=ingress-nginx-admission],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g4wd8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:*false,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod ingress-nginx-admission-create--1-ghwff_ingress-nginx(4986e1ae-a5af-4985-afd2-82982493093e): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f": dial tcp 142.251.8.82:443: i/o timeout
Apr 24 09:05:46 minikube kubelet[2720]: E0424 09:05:46.695465    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\": dial tcp 142.251.8.82:443: i/o timeout\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:05:58 minikube kubelet[2720]: E0424 09:05:58.274723    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:06:11 minikube kubelet[2720]: E0424 09:06:11.274169    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:06:17 minikube kubelet[2720]: E0424 09:06:17.073472    2720 remote_image.go:114] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:06:17 minikube kubelet[2720]: E0424 09:06:17.073575    2720 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 142.251.8.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:06:17 minikube kubelet[2720]: E0424 09:06:17.074444    2720 kuberuntime_manager.go:898] container &Container{Name:patch,Image:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f,Command:[],Args:[patch --webhook-name=ingress-nginx-admission --namespace=$(POD_NAMESPACE) --patch-mutating=false --secret-name=ingress-nginx-admission --patch-failure-policy=Fail],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ls4db,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:*false,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod ingress-nginx-admission-patch--1-7dr44_ingress-nginx(51e8fa5a-279a-409f-a32d-5e99b071461d): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f": dial tcp 142.251.8.82:443: i/o timeout
Apr 24 09:06:17 minikube kubelet[2720]: E0424 09:06:17.074556    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\": dial tcp 142.251.8.82:443: i/o timeout\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:06:22 minikube kubelet[2720]: E0424 09:06:22.275064    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:06:29 minikube kubelet[2720]: E0424 09:06:29.312520    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:06:41 minikube kubelet[2720]: E0424 09:06:41.289369    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:06:54 minikube kubelet[2720]: E0424 09:06:54.276090    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:07:07 minikube kubelet[2720]: E0424 09:07:07.645562    2720 remote_image.go:114] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:07:07 minikube kubelet[2720]: E0424 09:07:07.645668    2720 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:07:07 minikube kubelet[2720]: E0424 09:07:07.645793    2720 kuberuntime_manager.go:898] container &Container{Name:create,Image:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f,Command:[],Args:[create --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc --namespace=$(POD_NAMESPACE) --secret-name=ingress-nginx-admission],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g4wd8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:*false,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod ingress-nginx-admission-create--1-ghwff_ingress-nginx(4986e1ae-a5af-4985-afd2-82982493093e): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f": dial tcp 64.233.188.82:443: i/o timeout
Apr 24 09:07:07 minikube kubelet[2720]: E0424 09:07:07.645879    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\": dial tcp 64.233.188.82:443: i/o timeout\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:07:18 minikube kubelet[2720]: E0424 09:07:18.276779    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:07:23 minikube kubelet[2720]: E0424 09:07:23.041531    2720 secret.go:195] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Apr 24 09:07:23 minikube kubelet[2720]: E0424 09:07:23.041703    2720 nestedpendingoperations.go:301] Operation for "{volumeName:kubernetes.io/secret/9f3547d6-d075-4732-8c0e-6f1b8ba23b4d-webhook-cert podName:9f3547d6-d075-4732-8c0e-6f1b8ba23b4d nodeName:}" failed. No retries permitted until 2023-04-24 09:09:25.041652429 +0000 UTC m=+3850.896307698 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/9f3547d6-d075-4732-8c0e-6f1b8ba23b4d-webhook-cert") pod "ingress-nginx-controller-7695595dd9-ndkdm" (UID: "9f3547d6-d075-4732-8c0e-6f1b8ba23b4d") : secret "ingress-nginx-admission" not found
Apr 24 09:07:30 minikube kubelet[2720]: E0424 09:07:30.273289    2720 kubelet.go:1720] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[webhook-cert], unattached volumes=[kube-api-access-lj2nq webhook-cert]: timed out waiting for the condition" pod="ingress-nginx/ingress-nginx-controller-7695595dd9-ndkdm"
Apr 24 09:07:30 minikube kubelet[2720]: E0424 09:07:30.273390    2720 pod_workers.go:836] "Error syncing pod, skipping" err="unmounted volumes=[webhook-cert], unattached volumes=[kube-api-access-lj2nq webhook-cert]: timed out waiting for the condition" pod="ingress-nginx/ingress-nginx-controller-7695595dd9-ndkdm" podUID=9f3547d6-d075-4732-8c0e-6f1b8ba23b4d
Apr 24 09:07:30 minikube kubelet[2720]: E0424 09:07:30.319636    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:07:38 minikube kubelet[2720]: E0424 09:07:38.667617    2720 remote_image.go:114] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:07:38 minikube kubelet[2720]: E0424 09:07:38.667722    2720 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:07:38 minikube kubelet[2720]: E0424 09:07:38.668721    2720 kuberuntime_manager.go:898] container &Container{Name:patch,Image:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f,Command:[],Args:[patch --webhook-name=ingress-nginx-admission --namespace=$(POD_NAMESPACE) --patch-mutating=false --secret-name=ingress-nginx-admission --patch-failure-policy=Fail],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ls4db,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:*false,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod ingress-nginx-admission-patch--1-7dr44_ingress-nginx(51e8fa5a-279a-409f-a32d-5e99b071461d): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f": dial tcp 64.233.188.82:443: i/o timeout
Apr 24 09:07:38 minikube kubelet[2720]: E0424 09:07:38.668804    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\": dial tcp 64.233.188.82:443: i/o timeout\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:07:45 minikube kubelet[2720]: E0424 09:07:45.275508    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:07:54 minikube kubelet[2720]: E0424 09:07:54.275664    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:08:00 minikube kubelet[2720]: E0424 09:08:00.275193    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:08:08 minikube kubelet[2720]: E0424 09:08:08.275462    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:08:14 minikube kubelet[2720]: E0424 09:08:14.274622    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:08:20 minikube kubelet[2720]: E0424 09:08:20.274457    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:08:25 minikube kubelet[2720]: E0424 09:08:25.275118    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:08:33 minikube kubelet[2720]: E0424 09:08:33.299682    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:08:46 minikube kubelet[2720]: E0424 09:08:46.274199    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:08:58 minikube kubelet[2720]: E0424 09:08:58.273845    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:09:07 minikube kubelet[2720]: E0424 09:09:07.628394    2720 remote_image.go:114] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:09:07 minikube kubelet[2720]: E0424 09:09:07.628498    2720 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:09:07 minikube kubelet[2720]: E0424 09:09:07.628650    2720 kuberuntime_manager.go:898] container &Container{Name:create,Image:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f,Command:[],Args:[create --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc --namespace=$(POD_NAMESPACE) --secret-name=ingress-nginx-admission],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g4wd8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:*false,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod ingress-nginx-admission-create--1-ghwff_ingress-nginx(4986e1ae-a5af-4985-afd2-82982493093e): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f": dial tcp 64.233.188.82:443: i/o timeout
Apr 24 09:09:07 minikube kubelet[2720]: E0424 09:09:07.629764    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\": dial tcp 64.233.188.82:443: i/o timeout\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:09:23 minikube kubelet[2720]: E0424 09:09:23.274462    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:09:25 minikube kubelet[2720]: E0424 09:09:25.062260    2720 secret.go:195] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Apr 24 09:09:25 minikube kubelet[2720]: E0424 09:09:25.063171    2720 nestedpendingoperations.go:301] Operation for "{volumeName:kubernetes.io/secret/9f3547d6-d075-4732-8c0e-6f1b8ba23b4d-webhook-cert podName:9f3547d6-d075-4732-8c0e-6f1b8ba23b4d nodeName:}" failed. No retries permitted until 2023-04-24 09:11:27.063149886 +0000 UTC m=+3972.917805156 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/9f3547d6-d075-4732-8c0e-6f1b8ba23b4d-webhook-cert") pod "ingress-nginx-controller-7695595dd9-ndkdm" (UID: "9f3547d6-d075-4732-8c0e-6f1b8ba23b4d") : secret "ingress-nginx-admission" not found
Apr 24 09:09:36 minikube kubelet[2720]: E0424 09:09:36.288762    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:09:39 minikube kubelet[2720]: E0424 09:09:39.802203    2720 remote_image.go:114] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:09:39 minikube kubelet[2720]: E0424 09:09:39.802274    2720 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: Get \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\": dial tcp 64.233.188.82:443: i/o timeout" image="registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Apr 24 09:09:39 minikube kubelet[2720]: E0424 09:09:39.802358    2720 kuberuntime_manager.go:898] container &Container{Name:patch,Image:registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f,Command:[],Args:[patch --webhook-name=ingress-nginx-admission --namespace=$(POD_NAMESPACE) --patch-mutating=false --secret-name=ingress-nginx-admission --patch-failure-policy=Fail],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:POD_NAMESPACE,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ls4db,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:*false,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod ingress-nginx-admission-patch--1-7dr44_ingress-nginx(51e8fa5a-279a-409f-a32d-5e99b071461d): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: Get "https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f": dial tcp 64.233.188.82:443: i/o timeout
Apr 24 09:09:39 minikube kubelet[2720]: E0424 09:09:39.802406    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: Get \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/ingress-nginx/kube-webhook-certgen/manifests/sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\": dial tcp 64.233.188.82:443: i/o timeout\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:09:47 minikube kubelet[2720]: E0424 09:09:47.273626    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:09:48 minikube kubelet[2720]: E0424 09:09:48.273797    2720 kubelet.go:1720] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[webhook-cert], unattached volumes=[webhook-cert kube-api-access-lj2nq]: timed out waiting for the condition" pod="ingress-nginx/ingress-nginx-controller-7695595dd9-ndkdm"
Apr 24 09:09:48 minikube kubelet[2720]: E0424 09:09:48.273909    2720 pod_workers.go:836] "Error syncing pod, skipping" err="unmounted volumes=[webhook-cert], unattached volumes=[webhook-cert kube-api-access-lj2nq]: timed out waiting for the condition" pod="ingress-nginx/ingress-nginx-controller-7695595dd9-ndkdm" podUID=9f3547d6-d075-4732-8c0e-6f1b8ba23b4d
Apr 24 09:09:53 minikube kubelet[2720]: E0424 09:09:53.286765    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:09:59 minikube kubelet[2720]: E0424 09:09:59.276237    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:10:04 minikube kubelet[2720]: E0424 09:10:04.273749    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:10:12 minikube kubelet[2720]: E0424 09:10:12.961964    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e
Apr 24 09:10:17 minikube kubelet[2720]: E0424 09:10:17.274586    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"patch\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-patch--1-7dr44" podUID=51e8fa5a-279a-409f-a32d-5e99b071461d
Apr 24 09:10:26 minikube kubelet[2720]: E0424 09:10:26.274736    2720 pod_workers.go:836] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"create\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f\\\"\"" pod="ingress-nginx/ingress-nginx-admission-create--1-ghwff" podUID=4986e1ae-a5af-4985-afd2-82982493093e

* 
* ==> kubernetes-dashboard [1301ab0781d6] <==
* 2023/04/24 08:17:35 [2023-04-24T08:17:35Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:17:35 [2023-04-24T08:17:35Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:17:35 Getting list of namespaces
2023/04/24 08:17:35 [2023-04-24T08:17:35Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:17:39 [2023-04-24T08:17:39Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:17:39 Getting list of namespaces
2023/04/24 08:17:39 [2023-04-24T08:17:39Z] Incoming HTTP/1.1 GET /api/v1/replicaset/default?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/04/24 08:17:39 Getting list of all replica sets in the cluster
2023/04/24 08:17:39 [2023-04-24T08:17:39Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:17:39 received 0 resources from sidecar instead of 5
2023/04/24 08:17:39 received 0 resources from sidecar instead of 5
2023/04/24 08:17:39 [2023-04-24T08:17:39Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:39 [2023-04-24T08:33:39Z] Incoming HTTP/1.1 GET /api/v1/replicaset/default?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/04/24 08:33:39 Getting list of all replica sets in the cluster
2023/04/24 08:33:39 [2023-04-24T08:33:39Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:33:39 Getting list of namespaces
2023/04/24 08:33:39 [2023-04-24T08:33:39Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:39 received 0 resources from sidecar instead of 5
2023/04/24 08:33:39 received 0 resources from sidecar instead of 5
2023/04/24 08:33:39 [2023-04-24T08:33:39Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:41 [2023-04-24T08:33:41Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:33:41 Getting list of namespaces
2023/04/24 08:33:41 [2023-04-24T08:33:41Z] Incoming HTTP/1.1 GET /api/v1/replicaset/default?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/04/24 08:33:41 Getting list of all replica sets in the cluster
2023/04/24 08:33:41 [2023-04-24T08:33:41Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:41 received 0 resources from sidecar instead of 5
2023/04/24 08:33:41 received 0 resources from sidecar instead of 5
2023/04/24 08:33:41 [2023-04-24T08:33:41Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:43 [2023-04-24T08:33:43Z] Incoming HTTP/1.1 GET /api/v1/replicaset/default?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/04/24 08:33:43 Getting list of all replica sets in the cluster
2023/04/24 08:33:43 [2023-04-24T08:33:43Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:33:43 Getting list of namespaces
2023/04/24 08:33:43 [2023-04-24T08:33:43Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:43 received 0 resources from sidecar instead of 5
2023/04/24 08:33:43 received 0 resources from sidecar instead of 5
2023/04/24 08:33:43 [2023-04-24T08:33:43Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:45 [2023-04-24T08:33:45Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:33:45 Getting list of namespaces
2023/04/24 08:33:45 [2023-04-24T08:33:45Z] Incoming HTTP/1.1 GET /api/v1/replicaset/default?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/04/24 08:33:45 Getting list of all replica sets in the cluster
2023/04/24 08:33:45 [2023-04-24T08:33:45Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:33:45 received 0 resources from sidecar instead of 5
2023/04/24 08:33:45 received 0 resources from sidecar instead of 5
2023/04/24 08:33:45 [2023-04-24T08:33:45Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:47:30 [2023-04-24T08:47:30Z] Incoming HTTP/1.1 GET /api/v1/replicaset/default?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/04/24 08:47:30 Getting list of all replica sets in the cluster
2023/04/24 08:47:30 [2023-04-24T08:47:30Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:47:30 Getting list of namespaces
2023/04/24 08:47:30 [2023-04-24T08:47:30Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:47:30 received 0 resources from sidecar instead of 5
2023/04/24 08:47:30 received 0 resources from sidecar instead of 5
2023/04/24 08:47:30 [2023-04-24T08:47:30Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:47:31 [2023-04-24T08:47:31Z] Incoming HTTP/1.1 GET /api/v1/replicaset/default?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/04/24 08:47:31 Getting list of all replica sets in the cluster
2023/04/24 08:47:31 [2023-04-24T08:47:31Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/04/24 08:47:31 Getting list of namespaces
2023/04/24 08:47:31 [2023-04-24T08:47:31Z] Outcoming response to 127.0.0.1 with 200 status code
2023/04/24 08:47:31 received 0 resources from sidecar instead of 5
2023/04/24 08:47:31 received 0 resources from sidecar instead of 5
2023/04/24 08:47:31 [2023-04-24T08:47:31Z] Outcoming response to 127.0.0.1 with 200 status code

* 
* ==> storage-provisioner [a5b31f0fa285] <==
* I0424 08:05:53.766358       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0424 08:05:53.769221       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: connect: connection refused

* 
* ==> storage-provisioner [dee5c83f7a86] <==
* I0424 08:06:23.002411       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0424 08:06:26.887164       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0424 08:06:26.898086       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0424 08:06:44.376395       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0424 08:06:44.377256       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_fcfcff98-70e2-4e54-92c0-19de52b11157!
I0424 08:06:44.378362       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"241fa993-6a47-45a3-9a77-f949c9b9857d", APIVersion:"v1", ResourceVersion:"592", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_fcfcff98-70e2-4e54-92c0-19de52b11157 became leader
I0424 08:06:44.479268       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_fcfcff98-70e2-4e54-92c0-19de52b11157!

